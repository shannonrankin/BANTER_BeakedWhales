---
title: "beakerbanter_hawaii_tns"
author: "Taiki Sakai"
date: "2022-11-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# FALSE means it will used saved .rds files instead of re-processing
# TRUE will run everything from scratch - this will take a long time
freshRun <- FALSE
```

## Data Processing for Beaked Whales: Hawaii

Start by loading the required packages

```{r}
library(PAMpal)
library(banter)
library(rfPermute)
```

### PAMpal Processing 

Set up our PPS for the Hawaii dataset

```{r, eval=freshRun}
pps <- PAMpalSettings(db='hawaii/Database_JMc/', 
                      binaries = 'hawaii/Binaries_new/',
                      sr_hz='auto', 
                      winLen_sec=.0025, 
                      filterfrom_khz=10, 
                      filterto_khz=NULL)
```

Process data and save to file so we don't have to process again, comment out
processing and saving lines and uncomment reading line if you've already done this.
We'll also check to see if there were any warning messages during processing.

```{r, include=FALSE, eval=!freshRun}
data <- readRDS('hawaii/hiceas_study.rds')
```

```{r, eval=freshRun}
data <- processPgDetections(pps, mode='db', id='Hawaii_BBW')
saveRDS(data, 'hawaii/hiceas_study.rds')
# Double check warning messages
print(getWarnings(data)$message)
```

Assign species IDs according to original Pamguard labels, then relabel them 
for consistency across projects

```{r}
data <- setSpecies(data, 'pamguard')
reSpecies <- readRDS('hawaii/species.rds')
print(reSpecies)
data <- setSpecies(data, 'reassign', value=reSpecies)
```

Filtering out unwanted data before sending off to BANTER. First we only want
a subset of species (and we also rename these for clarity later). Second the
Hawaii data has issues with the second hydrophone, so we filter down to only
the first channel

```{r}
goodSpecies<- c("ZC", "MD", "BW", "BWC", "IP", "BW", "possBW")
data <- filter(data, species %in% goodSpecies)
data <- setSpecies(data, method='reassign',
                   value=data.frame(old=c('ZC', 'MD', 'BWC', 'IP'), new=c("Cuviers", "Blainsvilles", "CrossSeamount", "Indopacetus")))
ch1only <- filter(data, Channel == '1')
```

We also want to use ICI in one of our models, so we'll calculate that.

```{r}
ch1only <- calculateICI(ch1only, time='peakTime')
```

Now we can export for BANTER, dropping species codes that we won't use for
training. We want to compare ICI vs non-ICI models, so we'll export one without
ICI data. We'll save both of these so we have an easy starting point for BANTER.

```{r, eval=freshRun}
bntDataIci <- export_banter(ch1only, dropSpecies = c("BW", "possBW"), training=TRUE)
bntData <- export_banter(ch1only, dropSpecies = c('BW', 'possBW'), 
                         dropVars = c('All_ici'), training=TRUE)
saveRDS(bntData, file='hawaii/hiceas_bntData.rds')
saveRDS(bntData, file='hawaii/hiceas_bntDataIci.rds')
```

### BANTER Training

Train our non-ICI model first, check stability of detector models before running
full banter.

```{r, include=FALSE, eval=!freshRun}
bntMdl <- readRDS('hawaii/hiceas_bntMdl_5e31_10e34.rds')
```

```{r, eval=freshRun}
bntMdl <- initBanterModel(bntData$events)
# was 30e3 / 1 in SRs initial, too much memory. 5e3/1 is 210mb and takes ~10min
bntMdl <- addBanterDetector(bntMdl, bntData$detectors, ntree=5e3, sampsize=1, importance = TRUE)
```

Check for stability to see if we need more trees

```{r}
plotDetectorTrace(bntMdl, detector = paste0('Click_Detector_', 0:2))
plotDetectorTrace(bntMdl, detector = paste0('Click_Detector_', 3:5))
plotDetectorTrace(bntMdl, detector = paste0('Click_Detector_', 6))
summary(bntMdl)
```

Looks fine, run full event banter model

```{r, eval=freshRun}
bntMdl <- runBanterModel(bntMdl, ntree=10e3, sampsize=4)
summary(bntMdl)
```

Looks fine so lets save it. We're storing the tree/sampsize info in the filename

```{r, eval=freshRun}
saveRDS(bntMdl, 'hawaii/hiceas_bntMdl_5e31_10e34.rds')
```

Repeat for ICI model

```{r, include=FALSE, eval=!freshRun}
bntMdlIci <- readRDS('hawaii/hiceas_bntMdlIci_5e31_10e34.rds')
```

```{r, eval=freshRun}
bntMdlIci <- initBanterModel(bntDataIci$events)
# was 30e3 / 1 in SRs initial, too much memory. 5e3/1 is 210mb and takes ~10min
bntMdlIci <- addBanterDetector(bntMdlIci, bntDataIci$detectors, ntree=5e3, sampsize=1, importance = TRUE)
```

Check for stability to see if we need more trees

```{r}
plotDetectorTrace(bntMdlIci, detector = paste0('Click_Detector_', 0:2))
plotDetectorTrace(bntMdlIci, detector = paste0('Click_Detector_', 3:5))
plotDetectorTrace(bntMdlIci, detector = paste0('Click_Detector_', 6))
summary(bntMdlIci)
```



```{r, eval=freshRun}
bntMdlIci <- runBanterModel(bntMdlIci, ntree=10e3, sampsize=4)
summary(bntMdlIci)
```

Looks fine so lets save it. We're storing the tree/sampsize info in the filename

```{r, eval=freshRun}
saveRDS(bntMdlIci, 'hawaii/hiceas_bntMdlIci_5e31_10e34.rds')
```

### BANTER Analytics

First extract just the Random Forest part of our BANTER model for analysis. We'll
use the model with ICI included since that performed better.

```{r}
bntMdlRf <- getBanterModel(bntMdlIci)
```

Confusion Matrix

```{r, include=TRUE}
confusionMatrix(bntMdlRf)
```

Class Priors (Expected Error Rate)

```{r, include=TRUE}
classPriors(bntMdlRf, NULL)
```

Plot Confusion Matrix Heat Map

```{r, include=TRUE}
plotConfMat(bntMdlRf, title="ConfusionMatrix", plot=TRUE)
```

Plot Error Trace for Banter Model

```{r, include=TRUE}
plot(bntMdlRf)
```

PlotVotes

```{r, include=TRUE}
plotVotes(bntMdlRf)
```

Importance Heatmap

```{r, include=TRUE}
plotImportance(bntMdlRf, plot.type="heatmap")
```

Proximity Plot

```{r, include=TRUE}
plotProximity(bntMdlRf)
```

Plot Predicted Probabilities

```{r, include=TRUE}
plotPredictedProbs(bntMdlRf, bins=30, plot=TRUE)
```