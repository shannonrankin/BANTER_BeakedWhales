---
title: Open-Source machine learning BANTER acoustic classification of beaked whale echolocation pulses
author:
  - name: Shannon Rankin
    email: shannon.rankin@noaa.gov
    affiliations: 
        - id: SWFSC
          name: Southwest Fisheries Science Center
          department: Marine Mammal & Turtle Division
          address: 8901 La Jolla Shores Dr.
          city: La Jolla
          state: CA
          postal-code: 92037
    attributes:
        corresponding: true
    note: This is the first author footnote.
  - name: Taiki Sakai
    email: taiki.sakai@noaa.gov
    affiliations:
        - id: SWFSC
          name: Southwest Fisheries Science Center
          department: Marine Mammal & Turtle Division
          address: 8901 La Jolla Shores Dr.
          city: La Jolla
          state: CA
          postal-code: 92037
  - name: Frederick Archer
    email: eric.archer@noaa.gov
    affiliations:
        - id: SWFSC
          name: Southwest Fisheries Science Center
          department: Marine Mammal & Turtle Division
          address: 8901 La Jolla Shores Dr.
          city: La Jolla
          state: CA
          postal-code: 92037
  - name: Jay Barlow
    email: jaybarlow33@yahoo.com
    affilations:
        - id: SWFSC
          name: BarlowAGAD
          department: 
          address: 
          city: 
          state: 
          postal-code: 
        - ref: Barlow AGAD
  - name: Danielle Cholewiak
    email: danielle.cholewiak@noaa.gov
    affilations:
        - id: NEFSC
          name: Northeast Fisheries Science Center
          department: 
          address: 166 Water Street
          city: Woods Hole
          state: MA
          postal-code: 02543
  - name: Annamaria I. DeAngelis
    email: annamaria.deangelis@noaa.gov
    affilations:
        - id: NEFSC
          name: Northeast Fisheries Science Center
          department: 
          address: 166 Water Street
          city: Woods Hole
          state: MA
          postal-code: 02543
  - name: Jennifer L. K. McCullough
    email: jennifer.mccullough@noaa.gov
    affilations:
        - id: PIFSC
          name: Pacific Islands Fisheries Science Center
          department: 
          address: 1845 Wasp Blvd
          city: Honolulu
          state: HI
          postal-code: 96818
  - name: Erin Oleson
    email: erin.oleson@noaa.gov
    affilations:
        - id: PIFSC
          name: Pacific Islands Fisheries Science Center
          department: 
          address: 1845 Wasp Blvd
          city: Honolulu
          state: HI
          postal-code: 96818
  - name: Anne Simonis
    email: anne.simonis@noaa.gov
    affiliations:
        - id: SWFSC
          name: Southwest Fisheries Science Center
          department: Marine Mammal & Turtle Division
          address: 8901 La Jolla Shores Dr.
          city: La Jolla
          state: CA
          postal-code: 92037
  - name: Melissa Soldevilla
    email: melissa.soldevilla@noaa.gov
    affilations:
        - id: SEFSC
          name: Southeast Fisheries Science Center
          department: 
          address: 75 Virginia Beach Drive
          city: Miami
          state: FL
          postal-code: 33143
  - name: Jennifer S. Trickey
    email: jenny.trickey@noaa.gov
    affilations:
        - id: PIFSC
          name: Pacific Islands Fisheries Science Center
          department: 
          address: 1845 Wasp Blvd
          city: Honolulu
          state: HI
          postal-code: 96818
abstract: |
  Passive acoustic monitoring is increasingly used for assessing populations of marine mammals; however, analysis of large datasets is limited by our ability to easily classify sounds detected. Classification of beaked whale acoustic events, in particular, requires evaluation of multiple lines of evidence by expert analysts. Here we present a highly automated approach to acoustic detection and classification using supervised machine learning and open source software methods. Data from four large scale surveys of beaked whales (northwestern North Atlantic, southwestern North Atlantic, Hawaii, and eastern North Pacific) were analyzed using PAMGuard (acoustic detection), PAMpal (acoustic analysis) and BANTER (hierarchical random forest classifier). Overall classification accuracy ranged from 88% for the southwestern North Atlantic data to 97% for the northwestern North Atlantic. Results for many species could likely be improved with increased sample sizes, consideration of alternative automated detectors, and addition of relevant environmental features. These methods provide a highly automated approach to acoustic detection and classification using open source methods that can be readily adopted for other species and geographic regions.
keywords: 
  - bioacoustics
  - machine learning
  - random forest
  - species classification
  - marine mammals
  - passive acoustic monitoring
  - beaked whale
date: last-modified
bibliography: ../manuscript/bibliography.bib
link-citations: TRUE
format: docx
  
#  pdf: default
#  elsevier-pdf:
#    keep-tex: true
#    journal:
#      name: Ecological Informatics
#      formatting: preprint
#      model: 1p
#      cite-style: authoryear
---

```{r, load packages, include=FALSE}
library("easypackages")
libraries("tidyverse", "knitr", "kableExtra", "magick", "magrittr", "here")
here()
```

# Introduction

Passive acoustic monitoring (PAM) has proven to be a valuable tool for studying populations of marine mammals [@parijs_management_2009]; however, the value of these studies depends on our ability to identify the sources of the sounds we are monitoring. Historically, experienced acousticians have manually identified stereotyped sounds that could reliably be attributed to a given species, based on their spectral or temporal characteristics [@baumann-pickering_species-specific_2013]; [@bittle_review_2013]; [@rankin_source_2005]; [@soldevilla_classification_2008]. However, the dramatic increase in the quantity of recordings being made make it impossible for experienced acousticians to manually annotate it all. This has led to an increased need for the development of automated classification routines that can provide accurate species determinations from acoustic recordings.

Beaked whales are deep diving marine mammals found in offshore waters; their long dive intervals and cryptic surfacing behavior make them difficult to study using typical shipboard visual observation methods [@macleod_beaked_2018]. However, beaked whales make stereotyped echolocation signals in the form of frequency-modulated (FM) pulses that have temporal and spatial characteristics that can be used to differentiate species [@baumann-pickering_species-specific_2013]. Detection of beaked whale signals in large datasets is greatly expanding our understanding of their population structure and the potential impact of human activities on these species [@barlow_acoustic-based_2022]; [@baumann-pickering_spatio-temporal_2014]; [@simonis_passive_2020]. Unfortunately, manual classification of beaked whale echolocation pulses requires analysis by trained analysts using a number of visual aids to examine the call characteristics. Development of automated classification routines, if accurate, serves to improve the efficiency, reduce the subjectivity, and decrease the cost of analyzing large datasets.

BANTER (**B**io-**A**coustic eve**NT** classifi**ER**) is a supervised machine learning method originally developed for species identification of dolphin signals from acoustic recordings [@rankin_acoustic_2017]. This hierarchical Random Forest [@breiman_random_2001] event classifier combines information from independent classification models for each call type (e.g., whistles, echolocation pulses, and burst pulses for the dolphin-based model) into a model classifying a full acoustic event, which is defined as a discrete collection of calls during an encounter. The event classifier uses the distribution of species assignment probabilities for each call type, along with any event-level metrics (such as call rate). BANTER is very flexible and can accommodate any number of measures from any number of detectors.

While BANTER was designed to classify events by integrating information from multiple types of call detectors, relatively minor changes to a detector for a specific call type could yield different detector results. In the dolphin-based model [@rankin_acoustic_2017], settings for a whistle and moan detector were modified to improve performance at detecting burst pulses. This approach of applying output from multiple call detectors (of the same type but with different settings) suggests that perhaps BANTER could be used on species that only produce one call type (or where only one call type is to be analyzed), as long as the settings of the automated call detector were modified such that the results were different. This approach was successfully applied to classified echolocation pulses for narwhals and belugas [@zahn_acoustic_2021]. For species that primarily (or exclusively) produce echolocation pulses, BANTER may serve as an option for automated machine learning classification.

Here we applied BANTER acoustic classification to beaked whale detections from large acoustic datasets from the U.S. East Coast, Hawaii, and the U.S. West Coast. Acoustic data were analyzed by experienced acousticians to determine species identity, and these 'ground truth' classifications served as training data for the supervised BANTER models. Our goals were to identify an efficient and accurate automated approach to acoustic species identification of beaked whales, and to provide a framework for analysis that may serve for other PAM studies.

# Materials and Methods

## Field Data Collection

Passive acoustic data were collected during surveys conducted by the National Oceanographic and Atmospheric Administrations' (NOAA) research operations off the U.S. East Coast, the Hawaiian Islands, and the U.S. West Coast.

Recordings from the U.S. East Coast (western North Atlantic Ocean) were collected using towed hydrophone arrays during the 2016 AMAPPS II (Atlantic Marine Assessment Program for Protected Species) survey by Northeast Fisheries Science Center and Southeast Fisheries Science Center [@united_states_national_marine_fisheries_service_2016_2016]. AMAPPS II was subdivided into the northern (NAtlantic) and southern (SAtlantic) survey areas. The NAtlantic study area ranged from Massachusetts south to New Jersey (HB1603, Appendix A, [@united_states_national_marine_fisheries_service_2016_2016]) and recordings used in this analysis were collected with two hydrophones (HTI-96-min, High Tech Inc., Long Beach, MS) which recorded at a 192 kHz sample rate with a 1 kHz high pass filter (National Instruments USB-6356 A/D card, see @deangelis_description_2018 for more information). The SAtlantic area ranged from Delaware south to central Florida (GU1605, Appendix B, [@united_states_national_marine_fisheries_service_2016_2016]) and recordings used in this analysis were collected with two hydrophones (Reson TC4013, Teledyne Marine, Slangerup, Denmark) which recorded at a 500 kHz sample rate (custom 12 channel SailDAQ soundcard) and were decimated to 192 kHz with a 1 kHz high pass filter (see GU1605, Appendix B, [@united_states_national_marine_fisheries_service_2016_2016] for more information). The NAtlantic and SAtlantic recordings were treated as two separate datasets due to differences in hydrophone frequency responses and sensitivities.

Recordings from Hawaii were collected using drifting acoustic recorders during the 2017 HICEAS (Hawaiian Island Cetacean Ecosystem Assessment Survey, @mccullough_acoustic_2021, @yano_cetacean_2018). Drifting acoustic recorders were deployed at randomly selected locations within the Main Hawaiian Islands. Data were collected using SoundTrap ST4300 recorders (Ocean Acoustics, Auckland, New Zealand) sampled at 288 kHz with a duty cycle of 2 min on for every 10 minutes. Individual drifting recorders were deployed for 11 to 23 days (see @mccullough_acoustic_2021, @yano_cetacean_2018 for more detailed information).

Recordings from the eastern North Pacific Ocean off the U.S. West Coast (EPacific) were collected using drifting acoustic recorders during the 2018 CCES (California Current Ecosystem Survey) [@simonis_passive_2020]. Drifting recorders were deployed at 23 stations distributed throughout the California Current region; data from 15 of these included high quality acoustic data used in this analysis. Two types of drifting recorders were used: (1) SoundTrap ST4300 recorders (Ocean Acoustics, Auckland, New Zealand) and (2) Wildlife Acoustics SM3M recorders (Wildlife Acoustics, Maynard, MA). Recordings were duty cycled and recorded 2 minutes out of a variable 'off' time; recorders sampled at a minimum 256 kHz sample rate. Individual drifting recorders were deployed for 5-79 days (see @simonis_passive_2020 for more detailed information).

## Acoustic Data Analysis

All acoustic recordings were analyzed using PAMGuard software (versions 2.00.15c, 2.00.16e) with a suite of generic click classifiers within the Click Detector module (see @keating_summary_2013). Classifier sets were saved such that any click may be classified as more than one click type (using 'save classifier set' in Pamguard click classification window). Five general click classifiers were treated as spectral band click detectors (i.e., 2 -- 15 kHz, 15 -- 30 kHz, 30 -- 50 kHz, 50 -- 80 kHz, and \> 80 kHz). An additional sixth detector within the 30 -- 50 kHz peak frequency range considered the presence of a frequency sweep that is characteristic of beaked whale pulses (see @keating_summary_2013).

Echolocation signals that were identified as frequency-modulated pulses from beaked whales were then linked as PAMGuard "events" by experienced acoustic researchers. Events included all the pulses that were close to each other in time, had similar spectral and waveform characteristics, and were received at consistent bearing angles. For NAtlantic and SAtlantic datasets, acoustic detections of beaked whales using towed hydrophone arrays were further subdivided into putative individuals by identification of consecutive pulses along the same bearing angle in the bearing time plot (see @deangelis_using_2017).

Experienced acoustic researchers used multiple lines of evidence (PAMGuard click detector bearing time display, click waveform display, click spectrum, and wigner plots) to assess the species identity of the acoustic event. When the available characteristics were inconclusive, the species was considered an unidentified beaked whale. Data were saved within the PAMGuard database and binaries for downstream processing using the *PAMpal package* [@sakai_pampal_2021] in R v2022.07.02 [@r_core_team_r_2022].

Standard click metrics describing the spectral and temporal characteristics were measured from echolocation pulses using default values in *PAMpal* [@sakai_pampal_2023]. Inter-pulse interval (IPI) was calculated using the 'calculateICI' function in *PAMpal* and the mode of the IPI was identified for each beaked whale acoustic event. In addition, for the EPacific data, we used the 'matchEnvData' function in *PAMpal* to include ERDAPP environmental data [@simons_erddap_2022], including seafloor depth and seafloor gradient (both from erdSrtm30plusSeafloorGradient), as well as sea surface temperature (from jplMURSST41). A full consideration of environmental data for all regions was beyond the scope of this study.

Multiple models were created to better understand the value (and potential limitations) of the different suite of measurements. Models included standard click metrics (only) for all pulses in a beaked whale acoustic event (EC); the addition of IPI for each event (EC_IPI), and for the EPacific dataset we also included environmental variables (EC_IPI_ENV).

## BANTER Acoustic Classification

BANTER models were created using the *banter* package [@archer_banter_2022] in R v2022.07.02 [@r_core_team_r_2022]. Output from PAMGuard click detector modules were used to create the BANTER detector models, for a total of 6 detector models (one for each click detector used). For each detector model, BANTER creates a mean of the species classification probabilities for each call type, which is applied to the BANTER event model (in conjunction with any event-level variables). A minimum of two events per species and the complete suite of variables (no missing data) were required for training and testing of the classification model. Event level variables included IPI and environmental variables (for the EPacific dataset). The Random Forest models that BANTER is based on are largely driven by two parameters, the number of trees in the forest (*ntree*) and the number of samples randomly drawn to build each tree (*sampsize*). Small values of *sampsize* were selected to improve computational performance, but large values of *ntree* were used to obtain models with stable classification results [@rankin_banter_2021]. Model results were summarized using the *rfpermute* package [@archer_rfpermute_2022].

# Results

Four datasets from four different regions (NAtlantic, SAtlantic, Hawaii, EPacific) were analyzed for this study, and species included: Baird's beaked whales (*Berardius bairdii*), Blainville's beaked whales (*Mesoplodon densirostris*), Cross Seamount beaked whales [@mcdonald_acoustic_2009], Cuvier's beaked whales (*Ziphius cavirostris*), Gervais' beaked whales (*M. europaeus*), Hubbs' beaked whales (*M. carlhubbsi*), Longman's beaked whales (*Indopacetus pacificus*), Sowerby's beaked whales (*M. bidens*), Stejneger's beaked whales (*M. stejnegeri*), True's beaked whales (*M. mirus*), and unidentified beaked whale 'BW43' [@baumann-pickering_species-specific_2013]. Analyses were conducted separately for the different study areas due to differences in the data collection methods that precluded combining of datasets. Species and sample sizes varied by study area.

## NAtlantic

Species encountered in the NAtlantic dataset include Cuvier's beaked whales (n = 120), Gervais' beaked whales (n = 4), Sowerby's beaked whales (n = 6), and True's beaked whales (n = 76). BANTER classification models included (1) echolocation pulses (EC), and (2) echolocation pulses and IPI (EC_IPI).

For the NAtlantic dataset, the most accurate model included echolocation pulse metrics with IPI; this model had a modest increase in accuracy over the EC (only) model (EC_IPI model, Detector Model: *sampsize* = 3, *ntree* = 10,000; Event Model: *sampsize* = 3, *ntree* = 100,000). This model provided an overall correct classification rate of 97.5% for all four species (pct.correct in Confusion Matrix, @fig-natlantic a). Classification scores ranged from 75% for Gervais' beaked whales to 100% for Cuvier's and Sowerby's beaked whales. All classification results were greater than expected (Priors in @fig-natlantic a). Results from the EC_IPI model are presented here; results from the EC model were similar and can be found in supplementary materials (Supplement Fig. 1).

The proximity plot (@fig-natlantic b) provides a view of the distribution of events within the classification model space. For each event in the plot, the color of the central dot represents the true species identity, and the circle represents the BANTER classification result. This plot shows the degree of overlap between Gervais', Sowerby's, and True's beaked whales. Species classifications of events are resolved using additional features (mean assignment probabilities for each of the detectors in the detector model, as well as any event level variables), as seen in the ten most important features for predicting each species (importance heat map, @fig-natlantic c). The strength of classifications for each event can be seen in the distribution of votes for each species across the forest (@fig-natlantic d). In each frame of this figure, the events are represented as vertical slices along the x-axis, and the percentage of votes for each species is represented by their color along that vertical slice in the y-axis. This distribution shows strong assignment probabilities for most Cuvier's and Sowerby's beaked whale events, with greater variability in assignment for Gervais' and True's beaked whale events.

## SAtlantic

Species encountered in the SAtlantic study dataset include Blainville's beaked whales (n = 46), Cuvier's beaked whales (n = 111), Gervais' beaked whales (n = 77), Sowerby's beaked whales (n = 2), and True's beaked whales (n = 13). BANTER classification models included (1) echolocation pulses (EC), and (2) echolocation pulses and IPI (EC_IPI).

For the SAtlantic dataset, the most accurate model considered the echolocation pulse metrics and the IPI for an event (EC_IPI Model, Detector Model: *sampsize* = 4, *ntree* = 10,000; Event Model: *sampsize* = 1, *ntree* = 100,000) and provided an overall correct classification rate of 88.7% for all five species. Classification scores ranged from a low of 50% (Sowerby's beaked whale) to a high of 100% (True's beaked whale, @fig-satlantic); all classification results were greater than expected (Priors in @fig-natlantic a). The sample sizes for the BANTER model were kept low (event sampsize = 1) to retain Sowerby's beaked whale, which had a sample size of 2. Analysis with a larger sample size resulted in improved classification results for Cuvier's and Gervais' beaked whale (see Supplement Fig. 3 for EC_IPI_ALT), but resulted in the loss of Sowerby's in the final model. Results from the EC_IPI model are presented here; results from the EC and EC_IPI_ALT model can be found in supplementary materials (Supplement Fig. 2).

For this dataset, the two most important features are insufficient to differentiate species, as seen by the overlap in species distribution with these feature spaces in the proximity plot (@fig-satlantic b). Importance variables varied by species (importance heat map @fig-satlantic c), with IPI measurements having relatively low importance (@fig-satlantic c). The distribution of votes (@fig-satlantic d) shows relatively weak classification results; most events consisted of \<50% of the trees voting for the correct species.

## Hawaii

The Hawaii dataset consisted of 13 drifting recorders deployed within the Main Hawaiian Islands; species included Blainville's beaked whale (n = 521), Cross Seamount beaked whale (n = 76), Cuvier's beaked whale (n = 201), and Longman's beaked whale (n = 122). BANTER classification models included (1) echolocation pulses (EC), and (2) echolocation pulses and IPI (EC_IPI).

The most accurate model considered the echolocation pulses only (EC Model, Detector Model: *sampsize* = 10, *ntree* = 5,000; Event model: *sampsize* = 4, *ntree* = 10,000) and provided an overall correct classification rate of 92.3% for all four species. Classification scores ranged from a low of 86% (Cuvier's beaked whale) to 97.5% (Longman's beaked whale, @fig-hawaii). All classification results were greater than expected (Prior in @fig-hawaii a). Results from the EC model are presented here; results from EC_IPI model can be found in supplementary materials (Supplement Fig. 4).

Distinctive clusters can be seen for Longman's and Blainville's beaked whales, although there is overlap on these first two dimensions of the clusters for Cuvier's and Cross Seamount beaked whales (@fig-hawaii b). This overlap is resolved with different importance features for Cuvier's and Cross Seamount beaked whales as seen in the importance heat map (@fig-hawaii c), resulting in the low misclassification rates for these species (@fig-hawaii a confusion matrix). The distribution of votes (@fig-hawaii d) show strong classification results for most Blainville's, Cross Seamount, and Longman's beaked whales, with lower classification strength for many Cuvier's beaked whale events.

## EPacific

The EPacific dataset consisted of 15 drifting recorders deployed off the U.S. West Coast, and species included Baird's beaked whale (n = 29), unidentified beaked whale 'BW43' (n = 125), Cross Seamount beaked whale (n = 6), Cuvier's beaked whale (n = 926), Hubbs' beaked whale (n = 66), and Stejneger's beaked whale (n = 42). BANTER classification models included (1) echolocation pulses (EC), (2) echolocation pulses and IPI (EC_IPI), and (3) echolocation pulses, IPI, and environmental features (EC_IPI_ENV).

The best model considered the echolocation pulses, IPI, and environmental features (EC_IPI_ENV Model, Detector Model: *sampsize* = 1, *ntree* = 10,000; Event model: *sampsize* = 5, *ntree* = 10,000) and provided an overall correct classification rate of 91.9% for all six species. Classification scores ranged from a low of 91.2% (BW43) to 100% for Cross Seamount beaked whale (@fig-epacific a). All classification results were greater than expected (Prior in @fig-epacific a). Results from the EC_IPI_ENV model are presented here; results from the EC and EC_IPI model can be found in supplementary materials (Supplement Figs. 5).

There is considerable overlap in the primary feature space for all but BW43, as shown in the proximity plot (@fig-epacific b). IPI was among the most important classification variable for all species (@fig-epacific c importance heat map). The distribution of votes (@fig-epacific d) show relatively strong classification results for Baird's, Hubbs', and Stejneger's beaked whales.

# Discussion

The results for the four study areas varied from a low of 88.7% correct classification in the SAtlantic dataset to a high of 97.5% correct classification in the NAtlantic dataset. All species in all datasets had classification rates well above those expected by chance; however Cuvier's (SAtlantic, Hawaii), Sowerby's (SAtlantic), and Gervais' beaked whales (NAtlantic) had classification rates below 90%.

Several of our datasets included very low sample sizes for some species; however, low sample sizes did not always result in low classification scores. In the NAtlantic dataset, Sowerby's beaked whale (n=6) was correctly classified in 100% of the events, with strong assignment probabilities. The Sowerby's beaked whale events in the SAtlantic study and the Gervais' beaked whale events in the NAtlantic study consisted of weak classifications. This is likely due to both a small number of events (n = 2 for Sowerby's in SAtlantic and n = 4 for Gervais' in NAtlantic) combined with the small *sampsize* used in the BANTER model. In general, larger sample sizes should lead to improved overall classification results, and improved strength of these classification results (as indicated in the vote distributions).

While some species have distinctive differences in their pulse characteristics that can lead to strong classification despite small sample sizes (e.g. Sowerby's beaked whales in NAtlantic), other species, such as Cuvier's beaked whales, have significant variation in their pulse measurements.  For species with high variability in the predictor variables and an overlap in the range of these variables with other species, a large sample size is required to describe the true variability of these call measurements. Even with reasonably large sample sizes, the classification may suffer (e.g., SAtlantic Cuvier's beaked whale = 82.8% correct classification). We found that by increasing the *sampsize* in BANTER, we could increase the classification rate for this species in this area to 91.8% (see Supplement Fig.3). However, this resulted in the inability to include Sowerby's beaked whale in the final model. So, an increased sample size in Sowerby's would likely lead to increased classification results for other species in the model.

Previous application of BANTER to dolphin species in the California Current found that large sample sizes could result in strong classification of species where experienced acousticians are unable to differentiate species (e.g., long-beaked and short-beaked common dolphins, @rankin_acoustic_2017). This suggests that large increases in sample sizes may improve classification results for Cuvier's beaked whales.

Gervais' and True's beaked whales have similar pulse characteristics that make them difficult to differentiate and they require considerable expertise to classify manually [@deangelis_description_2018]. Our results suggest that BANTER may serve as an efficient and effective means of classifying and differentiating these two species. Despite modest sample sizes, Gervais' and True's beaked whales showed high classification scores in the SAtlantic (93.5% and 100%, respectively), and True's performed well in the NAtlantic. Unfortunately, we were unable to combine the Atlantic datasets (which would increase sample sizes of True's beaked whales) due to differences in hydrophone characteristics that resulted in differences in call metrics. Calibration of signals (to make them comparable) may allow for combining datasets to improve sample sizes.

In addition to poor classification of Gervais' in the NAtlantic study area, the plot votes show that for one of the four events, only a few of the 100,000 trees 'voted' for Gervais', and the majority of the votes were for True's beaked whales. Analysts' notes indicated uncertainty in manual species classification of this event in this dataset. While small sample size can at times provide good classification scores, as we found for Sowerby's beaked whale in this SAtlantic dataset, they can be heavily influential if there are inaccuracies in the training data.

These two examples of small sample sizes highlight a conflict in preferred protocol. Ideally, (1) all [species]{.underline} would be included in a classification model, so as to better represent the local species diversity, (2) all [events]{.underline} would ideally be included in the classification model, so as to better represent the variability found in the area, and (3) only confident 'ground truth' classifications would be considered in the training model. Unfortunately, in species where identity must be determined based on call characteristics (rather than visual confirmation of species identity in the field), it can sometimes be difficult to confidently determine species identity when calls are highly variable and do not include at least one call that provides high confidence of species identity. In the case of beaked whales, we recommend that training data include a high level of confidence for inclusion. This is especially critical for species with small sample sizes. An alternative is to require agreement from multiple analysts. This concern about accurate labeling of training data is further complicated by the potential existence of species that have not yet been identified. For example, [@barlow_unique_2022] recently discovered what appears to be a new species of beaked whale off Baja California, Mexico; this putative new species may have been detected but misclassified in other datasets (expert analysis did not identify these in the EPacific data presented here).

Inter-pulse interval (IPI) was found to be the most important variable for NAtlantic and EPacific, and IPI was the fourth and fifth ranked variables for SAtlantic (see importance heat maps for each survey area). While the addition of IPI did not improve results for data from Hawaii, results were similar and IPI ranked #9 in importance for the Hawaii study area. @baumann-pickering_species-specific_2013 showed an overlap in the IPI between Cuvier's and Blainville's beaked whales, but a strong difference in IPI between these species and Cross Seamount beaked whales. It is possible that classification of these species could be improved by refining an event to annotation at the individual level, as was done with the NAtlantic and SAtlantic datasets. Subdividing pulse trains into individuals in PAMGuard is time consuming, but alternative options include consideration of the PAMGuard click train detector module as an additional first stage detector in BANTER, or by developing a similar function in R to apply to events.

For this study, only a few simple environmental features were considered for one of the study areas (seafloor depth, seafloor gradient, and sea surface temperature). In the EPacific study area, inclusion of these variables increased the overall classification rate from 91.1% to 91.9%. These variables had the most impact on classification results for the Cross Seamount beaked whale (n = 6), raising the classification scores from 83.3% to 100%. Alternative environmental features may improve results for other species.

While BANTER provides an efficient and consistent approach to classification, there are significant limitations that must be considered. BANTER is a supervised machine learning tool and requires reliable training data for success. Training data should consist of labels with strong confidence in species identity (ideally determined by agreement from more than one analyst) and sample sizes should be large enough to explain the natural variability in the data.

The workflow presented here provides a highly automated approach to detection of acoustic events (PAMGuard), integration of environmental data (PAMpal), and acoustic event classification (BANTER). These methods significantly reduce manual analysis, provide more consistent classification results with fewer biases, and provide an estimate of classification error. The greatest improvement to classification results for beaked whales would likely result from improved sample sizes, and examination of individuals to accurately measure IPI. Consideration of additional detectors (e.g., matched filter detector, click train detector) or additional environmental variables may further improve classification results. Improved alignment of detection methods across studies (i.e., definition of events, hydrophone calibration) may allow for combining data within geographic regions to improve assessments within regions for all species, and across regions for species with global distributions, such as Cuvier's beaked whales. These highly automated methods may allow for analysis of data across large spatial and temporal scales to address large ecological and population level questions.

# Acknowledgements

The authors would like to acknowledge the large number of scientists and shipboard crew who were responsible for data collection during multiple large scale studies. Thanks to Liam Mueller-Brennan for their help with data analysis. Sea surface temperature data were provided by JPL under support by the NASA MEaSUREs program. Funding for data collection and analysis were provided by the U.S. Navy, the Bureau of Ocean Energy Management, and the National Oceanographic and Atmospheric Administration. The AMAPPS study (NAtlantic/SAtantic) was funded in part by the U.S. Department of the Interior, Bureau of Ocean Energy Management, Environmental Studies Program, Washington, DC, through Inter-Agency Agreement Number M10PG00075 with the National Marine Fisheries Service as the Atlantic Marine Assessment Program for Protected Species. The HICEAS 2017 Survey (Hawaii) was funded by Bureau of Ocean Energy Management under (IAA M17PG00024) and NMFS Pacific Islands Fisheries Science Center. The CCES Survey (EPacific) was funded by Bureau of Ocean Energy Management (No. M17PG00025), U.S. Navy Pacific Fleet Environmental Readiness Division (IAA No. N00070-18-MP-4C560) and Chief of Naval Operations N45, and Southwest Fisheries Science Center. The manuscript was improved thanks to reviews from XX and XX.

# Figures and tables



```{r, natlantic}
#| label: fig-natlantic
#| fig-cap: BANTER classification results from the NAtlantic dataset including echolocation pulses and inter-pulse interval (EC_IPI). Confusion matrix (a) provides the percent correct classification for each species (pct.correct), lower confidence intervals (LCI_0.95), upper confidence intervals (UCI_0.95), and priors (expected error rate). Proximity plot (b) for species events from BANTER model (central dot color represents true species identity; color of circle surrounding dot represents BANTER species classification). Heat map (c) for ranks of ten most important variables; colors scale from most important predictors (dark red) to least important predictors (dark blue). Vote Plot (d) shows the vote distribution for each event (vertical slice) for each species; distribution of votes by species is shown by their representative color.
#| fig-width: 10
#| fig-height: 10
#| fig-align: center
#| out-width: 100%
#| echo: false
confuse <- magick::image_read('manuscript_files/natlantic_ici_confuseMatrix.png')%>%
  image_border(color="#ffffff", geometry = "50x130")%>%
  image_annotate("a) Confusion Matrix", size=100, color = "black")
vote <- magick::image_read('manuscript_files/natlantic_ici_votes.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_annotate("d) Vote Plot", size=100, color = "black")
prox <- magick::image_read('manuscript_files/natlantic_ici_proximity.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_annotate("b) Proximity Plot", size=100, color = "black")
heat <- magick::image_read('manuscript_files/natlantic_ici_importance.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_scale("3300")%>%
  image_annotate("c) Importance Heat Map", size=100, color = "black")
  
natlantic_ici_Figure <-image_append(c(prox, heat, vote))
natlantic_ici_Figure<- image_append(c(confuse, natlantic_ici_Figure), stack=TRUE)
print(natlantic_ici_Figure, info=FALSE)
```
\newpage

```{r, satlantic}
#| label: fig-satlantic
#| fig-cap: BANTER classification results from the SAtlantic dataset (EC_IPI). Confusion matrix (a) provides the percent correct classification for each species (pct.correct), lower confidence intervals (LCI_0.95), upper confidence intervals (UCI_0.95), and priors (expected error rate). Proximity plot (b) for species events from BANTER model (central dot color represents true species identity; color of circle surrounding dot represents BANTER species classification). Heat map (c) for ranks of ten most important variables; colors scale from most important predictors (dark red) to least important predictors (dark blue). Vote Plot (d) shows the vote distribution for each event (vertical slice) for each species; distribution of votes by species is shown by their representative color.
#| fig-width: 10
#| fig-height: 10
#| fig-align: center
#| out-width: 100%
#| echo: false
confuse <- magick::image_read('manuscript_files/satlantic_ici_confuseMatrix.png')%>%
  image_border(color="#ffffff", geometry = "50x130")%>%
  image_annotate("a) Confusion Matrix", size=100, color = "black")
vote <- magick::image_read('manuscript_files/satlantic_ici_votes.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_annotate("d) Vote Plot", size=100, color = "black")
prox <- magick::image_read('manuscript_files/satlantic_ici_proximity.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_annotate("b) Proximity Plot", size=100, color = "black")
heat <- magick::image_read('manuscript_files/satlantic_ici_importance.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_scale("3300")%>%
  image_annotate("c) Importance Heat Map", size=100, color = "black")
  
satlantic_ici_Figure <-image_append(c(prox, heat, vote))
satlantic_ici_Figure<- image_append(c(confuse, satlantic_ici_Figure), stack=TRUE)
print(satlantic_ici_Figure, info=FALSE)
```
\newpage
```{r, hawaii}
#| label: fig-hawaii
#| fig-cap: BANTER classification results from the Hawaii dataset (EC). Confusion matrix (a) provides the percent correct classification for each species (pct.correct), lower confidence intervals (LCI_0.95), upper confidence intervals (UCI_0.95), and priors (expected error rate). Proximity plot (b) for species events from BANTER model (central dot color represents true species identity; color of circle surrounding dot represents BANTER species classification). Heat map (c) for ranks of ten most important variables; colors scale from most important predictors (dark red) to least important predictors (dark blue). Vote Plot (d) shows the vote distribution for each event (vertical slice) for each species; distribution of votes by species is shown by their representative color.
#| fig-width: 10
#| fig-height: 10
#| fig-align: center
#| out-width: 100%
#| echo: false
confuse <- magick::image_read('manuscript_files/hawaii_ec_confuseMatrix.png')%>%
  image_border(color="#ffffff", geometry = "50x130")%>%
  image_annotate("a) Confusion Matrix", size=100, color = "black")
vote <- magick::image_read('manuscript_files/hawaii_ec_votes.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_annotate("d) Vote Plot", size=100, color = "black")
prox <- magick::image_read('manuscript_files/hawaii_ec_proximity.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_annotate("b) Proximity Plot", size=100, color = "black")
heat <- magick::image_read('manuscript_files/hawaii_ec_importance.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_scale("3300")%>%
  image_annotate("c) Importance Heat Map", size=100, color = "black")
  
hawaii_ec_Figure <-image_append(c(prox, heat, vote))
hawaii_ec_Figure<- image_append(c(confuse, hawaii_ec_Figure), stack=TRUE)
print(hawaii_ec_Figure, info=FALSE)
```
\newpage
```{r, epacific-env}
#| label: fig-epacific
#| fig-cap: BANTER classification results from the EPacific dataset with environmental data (EC_IPI_ENV). Confusion matrix (a) provides the percent correct classification for each species (pct.correct), lower confidence intervals (LCI_0.95), upper confidence intervals (UCI_0.95), and priors (expected error rate). Proximity plot (b) for species events from BANTER model (central dot color represents true species identity; color of circle surrounding dot represents BANTER species classification). Heat map (c) for ranks of ten most important variables; colors scale from most important predictors (dark red) to least important predictors (dark blue). Vote Plot (d) shows the vote distribution for each event (vertical slice) for each species; distribution of votes by species is shown by their representative color.
#| fig-width: 10
#| fig-height: 10
#| fig-align: center
#| out-width: 100%
#| echo: false
confuse <- magick::image_read('manuscript_files/epacific_env_confuseMatrix.png')%>%
  image_border(color="#ffffff", geometry = "50x130")%>%
  image_annotate("a) Confusion Matrix", size=100, color = "black")
vote <- magick::image_read('manuscript_files/epacific_env_votes.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_annotate("d) Vote Plot", size=100, color = "black")
prox <- magick::image_read('manuscript_files/epacific_env_proximity.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_annotate("b) Proximity Plot", size=100, color = "black")
heat <- magick::image_read('manuscript_files/epacific_env_importance.png')%>%
  image_border(color="#ffffff", geometry = "270x130")%>%
  image_scale("3300")%>%
  image_annotate("c) Importance Heat Map", size=100, color = "black")
  
epacific_env_Figure <-image_append(c(prox, heat, vote))
epacific_env_Figure<- image_append(c(confuse, epacific_env_Figure), stack=TRUE)
print(epacific_env_Figure, info=FALSE)
```
\newpage
# References {.unnumbered}
