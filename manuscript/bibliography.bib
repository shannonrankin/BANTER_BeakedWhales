
@software{r_core_team_r_2022,
	location = {Vienna, Austria},
	title = {R: A language and environment for statistical computing},
	url = {http://www.R-project.org/},
	version = {4.2.2},
	publisher = {R Foundation for Statistical Computing},
	editora = {R Core Team},
	editoratype = {collaborator},
	date = {2022},
}

@unpublished{sakai_pampal_2023,
	title = {{PAMpal}: An R package for streamlined and standardized analysis of passive acoustic data},
	pagetotal = {15},
	author = {Sakai, Taiki and Rankin, Shannon},
	date = {2023},
}

@article{united_states_national_marine_fisheries_service_2016_2016,
	title = {2016 Annual Report of a Comprehensive Assessment of Marine Mammal, Marine Turtle, and Seabird Abundance and Spatial Distribution in {US} Waters of the Western North Atlantic Ocean – {AMAPPS} {II}},
	url = {https://repository.library.noaa.gov/view/noaa/22663},
	doi = {10.25923/GBAP-G480},
	author = {{United States National Marine Fisheries Service}},
	urldate = {2023-06-30},
	date = {2016},
	note = {Publisher: Northeast Fisheries Science Center (U.S.).  Southeast Fisheries Science Center (U.S.).},
}

@article{deangelis_using_2017,
	title = {Using multipath reflections to obtain dive depths of beaked whales from a towed hydrophone array},
	volume = {142},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/1.4998709},
	doi = {10.1121/1.4998709},
	abstract = {Beaked whales are deep divers, emitting echolocation clicks while at depth. Little is known about the dive behavior of most species; however, passive acoustic data collected with towed hydrophone arrays can provide depth information using multipath reflections of clicks coupled with a two-dimensional localization of the individual. Data were collected during a shipboard survey in the western North Atlantic Ocean using a towed linear hydrophone array. Beaked whale tracks were classified as either Cuvier's (Ziphius cavirostris) or Gervais'/True's (Mesoplodon europaeus/Mesoplodon mirus). Weighted species average depths and weighted species standard deviations were 1158 m ± 287 m for Cuvier's (n = 24), and 870 m ± 151 m for Gervais'/True's (n = 15). Depth uncertainties ranged from 3\% to 142\% of the average depth. Slant ranges were corrected for depth to provide average horizontal perpendicular distance estimates. The average horizontal perpendicular distance distribution exhibited fewer detections in the first bin than the second. This is the first report of dive depths for Gervais'/True's beaked whales and use of this method to obtain depths for beaked whales using a towed linear array.},
	pages = {1078--1087},
	number = {2},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {{DeAngelis}, Annamaria Izzi and Valtierra, Robert and Van Parijs, Sofie M. and Cholewiak, Danielle},
	urldate = {2023-08-15},
	date = {2017-08-23},
	file = {Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\YZZX34G7\\Using-multipath-reflections-to-obtain-dive-depths.html:text/html},
}

@article{mccullough_acoustic_2021,
	title = {An acoustic survey in the main Hawaiian Islands using drifting recorders},
	volume = {H-21-04},
	url = {https://repository.library.noaa.gov/view/noaa/29490},
	doi = {10.25923/RZZZ-0V38},
	abstract = {During the 2017 Hawaiian Islands Cetacean and Ecosystem Assessment Survey ({HICEAS}), 19 drifting hydrophone recorders were deployed around the main Hawaiian Islands with the goal of improving detection of beaked whales and Kogia. These Drifting Acoustic Spar Buoy Recorders ({DASBRs}) contained a two-element vertical hydrophone array at 150 m depth, sampling at 288 {kHz} for 2 of every 10 min. Deployment locations were planned to cover a 50 nmi minimum convex polygon around the main Hawaiian Islands ({MHI} Stratum). In actuality, {DASBRs} drifted significantly within the {MHI} Stratum and up to 200 nmi beyond. Overall, the {DASBRs} collected data over a 96-day period and over 6,354 km of drifting track. Using the Click Detector Module within {PAMGuard} (version 2.00.11), cetacean echolocation pulses within 2-min periods were classified to species based on peak frequency and other pulse characteristics. We found frequency modulated ({FM}) pulses characteristic of Longman’s, Cuvier’s, Blainville’s, and Cross Seamount beaked whales ({BWC}) in 928 of the 2-min files, spread along the drift track of each {DASBR}. Additionally, two types of Kogia spp. echolocation clicks were detected with peak frequencies of 116 {kHz} and 123 {kHz}. To further improve detections of Kogia spp. echolocation clicks, custom {MATLAB} subroutines were used to re-analyze the recordings in greater detail resulting in 60 2-min detections versus the original 13 detected with these {PAMGuard} classifiers. Detections of sperm whales (in 2,809 2-min files) and echolocation from unidentified odontocetes (in 3,939 2-min files) were also identified. Acoustic detections of beaked whales and Kogia spp. were much more numerous than those from the towed array efforts during {HICEAS} 2017 and will enhance understanding of the distribution of these species in the main Hawaiian Islands.},
	pages = {26},
	journaltitle = {{PIFSC} Administrative Report},
	author = {{McCullough}, Jennifer L. K. and Oleson, Erin M. and Barlow, Jay and Allen, Ann N. and Merkens, Karlina P. B.},
	urldate = {2023-07-24},
	date = {2021},
	note = {Publisher: Pacific Islands Fisheries Science Center (U.S.)},
}

@article{mccullough_acoustic_2021-1,
	title = {Acoustic classification of false killer whales in the Hawaiian islands based on comprehensive vocal repertoire},
	volume = {1},
	issn = {2691-1191},
	url = {https://doi.org/10.1121/10.0005512},
	doi = {10.1121/10.0005512},
	abstract = {Use of underwater passive acoustic datasets for species-specific inference requires robust classification systems to identify encounters to species from characteristics of detected sounds. A suite of routines designed to efficiently detect cetacean sounds, extract features, and classify the detection to species is described using ship-based, visually verified detections of false killer whales (Pseudorca crassidens). The best-performing model included features from clicks, whistles, and burst pulses, which correctly classified 99.6\% of events. This case study illustrates use of these tools to build classifiers for any group of cetacean species and assess classification confidence when visual confirmation is not available.},
	pages = {071201},
	number = {7},
	journaltitle = {{JASA} Express Letters},
	shortjournal = {{JASA} Express Letters},
	author = {{McCullough}, Jennifer L. K. and Simonis, Anne E. and Sakai, Taiki and Oleson, Erin M.},
	urldate = {2023-07-24},
	date = {2021-07-13},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\PQW5IWIA\\McCullough et al. - 2021 - Acoustic classification of false killer whales in .pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\KJQ85LCW\\Acoustic-classification-of-false-killer-whales-in.html:text/html},
}

@article{breiman_random_2001,
	title = {Random Forests},
	volume = {45},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	pages = {5--32},
	number = {1},
	journaltitle = {Machine Learning},
	shortjournal = {Machine Learning},
	author = {Breiman, Leo},
	urldate = {2023-06-30},
	date = {2001-10-01},
	langid = {english},
	keywords = {classification, ensemble, regression},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\7AKVAUSL\\Breiman - 2001 - Random Forests.pdf:application/pdf},
}

@software{sakai_pammisc_2023,
	title = {{PAMmisc}: Miscellaneous Functions for Passive Acoustic Analysis},
	url = {https://cran.r-project.org/web/packages/PAMmisc/index.html},
	version = {R package version 1.11.4},
	author = {Sakai, Taiki},
	date = {2023},
}

@software{noauthor_notitle_nodate,
}

@article{miksis-olds_exploring_nodate,
	title = {Exploring the Ocean Through Soundscapes},
	author = {Miksis-Olds, Jennifer L and Martin, Bruce and Tyack, Peter L},
	langid = {english},
	file = {Miksis-Olds et al. - Exploring the Ocean Through Soundscapes.pdf:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\8XF9Q2A6\\Miksis-Olds et al. - Exploring the Ocean Through Soundscapes.pdf:application/pdf},
}

@article{miksis-olds_exploring_nodate-1,
	title = {Exploring the Ocean Through Soundscapes},
	author = {Miksis-Olds, Jennifer L and Martin, Bruce and Tyack, Peter L},
	langid = {english},
	file = {Miksis-Olds et al. - Exploring the Ocean Through Soundscapes.pdf:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\U8U44W9S\\Miksis-Olds et al. - Exploring the Ocean Through Soundscapes.pdf:application/pdf},
}

@software{simons_erddap_2022,
	location = {Monterey, {CA}},
	title = {{ERDDAP}},
	url = {https://coastwatch.pfeg.noaa.gov/erddap},
	publisher = {{NOAA}/{NMFS}/{SWFSC}/{ERD}},
	author = {Simons, R. A. and John, Chris},
	date = {2022},
}

@article{noauthor_unique_nodate,
	title = {Unique morphological and acoustic characteristics of beaked whales (Mesoplodon sp.) off the west coast of Baja California, Mexico},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/mms.12853},
	doi = {10.1111/mms.12853},
	urldate = {2023-05-22},
	langid = {english},
	file = {Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\NUQA8HVN\\mms.html:text/html},
}

@article{simonis_passive_2020,
	title = {Passive Acoustic Survey Of Deep-Diving Odontocetes in the California Current Ecosystem 2018: Final Report},
	url = {https://repository.library.noaa.gov/view/noaa/27223},
	doi = {10.25923/W5XX-JZ73},
	shorttitle = {Passive Acoustic Survey Of Deep-Diving Odontocetes in the California Current Ecosystem 2018},
	journaltitle = {{NOAA}-{TM}-{NMFS}-{SWFSC}-630},
	author = {Simonis, Anne E.},
	urldate = {2023-05-12},
	date = {2020},
	note = {Publisher: Southwest Fisheries Science Center (U.S.)},
}

@article{fregosi_comparison_2020,
	title = {Comparison of fin whale 20 Hz call detections by deep-water mobile autonomous and stationary recorders},
	volume = {147},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/10.0000617},
	doi = {10.1121/10.0000617},
	abstract = {Acoustically equipped deep-water mobile autonomous platforms can be used to survey for marine mammals over intermediate spatiotemporal scales. Direct comparisons to fixed recorders are necessary to evaluate these tools as passive acoustic monitoring platforms. One glider and two drifting deep-water floats were simultaneously deployed within a deep-water cabled hydrophone array to quantitatively assess their survey capabilities. The glider was able to follow a pre-defined track while float movement was somewhat unpredictable. Fin whale (Balaenoptera physalus) 20 Hz pulses were recorded by all hydrophones throughout the two-week deployment. Calls were identified using a template detector, which performed similarly across recorder types. The glider data contained up to 78\% fewer detections per hour due to increased low-frequency flow noise present during glider descents. The glider performed comparably to the floats and fixed recorders at coarser temporal scales; hourly and daily presence of detections did not vary by recorder type. Flow noise was related to glider speed through water and dive state. Glider speeds through water of 25 cm/s or less are suggested to minimize flow noise and the importance of glider ballasting, detector characterization, and normalization by effort when interpreting glider-collected data and applying it to marine mammal density estimation are discussed.},
	pages = {961--977},
	number = {2},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Fregosi, Selene and Harris, Danielle V. and Matsumoto, Haruyoshi and Mellinger, David K. and Negretti, Christina and Moretti, David J. and Martin, Stephen W. and Matsuyama, Brian and Dugan, Peter J. and Klinck, Holger},
	urldate = {2023-04-28},
	date = {2020-02-10},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\LJ8XWRYH\\Fregosi et al. - 2020 - Comparison of fin whale 20 Hz call detections by d.pdf:application/pdf},
}

@article{fregosi_detection_2022,
	title = {Detection probability and density estimation of fin whales by a Seaglider},
	volume = {152},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/10.0014793},
	doi = {10.1121/10.0014793},
	abstract = {A single-hydrophone ocean glider was deployed within a cabled hydrophone array to demonstrate a framework for estimating population density of fin whales (Balaenoptera physalus) from a passive acoustic glider. The array was used to estimate tracks of acoustically active whales. These tracks became detection trials to model the detection function for glider-recorded 360-s windows containing fin whale 20-Hz pulses using a generalized additive model. Detection probability was dependent on both horizontal distance and low-frequency glider flow noise. At the median 40-Hz spectral level of 97 {dB} re 1 μPa2/Hz, detection probability was near one at horizontal distance zero with an effective detection radius of 17.1 km [coefficient of variation ({CV}) = 0.13]. Using estimates of acoustic availability and acoustically active group size from tagged and tracked fin whales, respectively, density of fin whales was estimated as 1.8 whales per 1000 km2 ({CV} = 0.55). A plot sampling density estimate for the same area and time, estimated from array data alone, was 1.3 whales per 1000 km2 ({CV} = 0.51). While the presented density estimates are from a small demonstration experiment and should be used with caution, the framework presented here advances our understanding of the potential use of gliders for cetacean density estimation.},
	pages = {2277--2291},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Fregosi, Selene and Harris, Danielle V. and Matsumoto, Haruyoshi and Mellinger, David K. and Martin, Stephen W. and Matsuyama, Brian and Barlow, Jay and Klinck, Holger},
	urldate = {2023-04-28},
	date = {2022-10-21},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\9HBTC2DE\\Fregosi et al. - 2022 - Detection probability and density estimation of fi.pdf:application/pdf},
}

@inproceedings{moloney_observeramar_2018,
	title = {Observer/{AMAR} G4 Passive Acoustic Monitoring System for Autonomous Maritime Observation},
	doi = {10.1109/AUV.2018.8729796},
	abstract = {The features of a new generation of Passive Acoustic Monitoring ({PAM}) electronics, algorithms, and associated software are described. {JASCO}'s “Observer/{AMAR} G4” is a family of components configured to deliver a wide spectrum of functionality to users and researchers. The capabilities of the Observer/{AMAR} family of components are described via a walkthrough of recent Observer/{AMAR} glider deployments and trials, with a focus on functionality, collected data, and lessons learned. The trials include an Observer-based Slocum glider (Teledyne Webb Research) deployed in the Gulf of St. Lawrence, Atlantic Canada, in search of endangered North Atlantic right whales. Installations and test deployments in Seaglider (Kongsberg) on the west coast of Norway and in {SEAEXPLORER} ({ALSEAMAR}) on the south coast of France are also described. The development and the beneficial capabilities of these novel systems are described, as well as the results from these trial deployments.},
	eventtitle = {2018 {IEEE}/{OES} Autonomous Underwater Vehicle Workshop ({AUV})},
	pages = {1--9},
	booktitle = {2018 {IEEE}/{OES} Autonomous Underwater Vehicle Workshop ({AUV})},
	author = {Moloney, John and Cole, Art and Hillis, Craig and Kowarski, Katie and {MacDonald}, Blair and Pedersen, Geir and Tassara, Luca and Camus, Lionel},
	date = {2018-11},
	note = {{ISSN}: 2377-6536},
	keywords = {Acoustics, Clocks, detectors, Floors, glider, in-situ, Monitoring, north Atlantic right whales, Observers, passive Acoustic Monitoring ({PAM}), real-time, Real-time systems, recording, Sonar equipment, Unmanned Underwater Vehicle ({UUV})},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\A245JHZF\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\U7SILMHG\\Moloney et al. - 2018 - ObserverAMAR G4 Passive Acoustic Monitoring Syste.pdf:application/pdf},
}

@article{fregosi_detection_2022-1,
	title = {Detection probability and density estimation of fin whales by a Seaglider},
	volume = {152},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/10.0014793},
	doi = {10.1121/10.0014793},
	abstract = {A single-hydrophone ocean glider was deployed within a cabled hydrophone array to demonstrate a framework for estimating population density of fin whales (Balaenoptera physalus) from a passive acoustic glider. The array was used to estimate tracks of acoustically active whales. These tracks became detection trials to model the detection function for glider-recorded 360-s windows containing fin whale 20-Hz pulses using a generalized additive model. Detection probability was dependent on both horizontal distance and low-frequency glider flow noise. At the median 40-Hz spectral level of 97 {dB} re 1 μPa2/Hz, detection probability was near one at horizontal distance zero with an effective detection radius of 17.1 km [coefficient of variation ({CV}) = 0.13]. Using estimates of acoustic availability and acoustically active group size from tagged and tracked fin whales, respectively, density of fin whales was estimated as 1.8 whales per 1000 km2 ({CV} = 0.55). A plot sampling density estimate for the same area and time, estimated from array data alone, was 1.3 whales per 1000 km2 ({CV} = 0.51). While the presented density estimates are from a small demonstration experiment and should be used with caution, the framework presented here advances our understanding of the potential use of gliders for cetacean density estimation.},
	pages = {2277--2291},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Fregosi, Selene and Harris, Danielle V. and Matsumoto, Haruyoshi and Mellinger, David K. and Martin, Stephen W. and Matsuyama, Brian and Barlow, Jay and Klinck, Holger},
	urldate = {2023-04-28},
	date = {2022-10-21},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\WTMLRBY7\\Fregosi et al. - 2022 - Detection probability and density estimation of fi.pdf:application/pdf},
}

@article{besson_towards_2022,
	title = {Towards the fully automated monitoring of ecological communities},
	volume = {25},
	issn = {1461-0248},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ele.14123},
	doi = {10.1111/ele.14123},
	abstract = {High-resolution monitoring is fundamental to understand ecosystems dynamics in an era of global change and biodiversity declines. While real-time and automated monitoring of abiotic components has been possible for some time, monitoring biotic components—for example, individual behaviours and traits, and species abundance and distribution—is far more challenging. Recent technological advancements offer potential solutions to achieve this through: (i) increasingly affordable high-throughput recording hardware, which can collect rich multidimensional data, and (ii) increasingly accessible artificial intelligence approaches, which can extract ecological knowledge from large datasets. However, automating the monitoring of facets of ecological communities via such technologies has primarily been achieved at low spatiotemporal resolutions within limited steps of the monitoring workflow. Here, we review existing technologies for data recording and processing that enable automated monitoring of ecological communities. We then present novel frameworks that combine such technologies, forming fully automated pipelines to detect, track, classify and count multiple species, and record behavioural and morphological traits, at resolutions which have previously been impossible to achieve. Based on these rapidly developing technologies, we illustrate a solution to one of the greatest challenges in ecology: the ability to rapidly generate high-resolution, multidimensional and standardised data across complex ecologies.},
	pages = {2753--2775},
	number = {12},
	journaltitle = {Ecology Letters},
	author = {Besson, Marc and Alison, Jamie and Bjerge, Kim and Gorochowski, Thomas E. and Høye, Toke T. and Jucker, Tommaso and Mann, Hjalte M. R. and Clements, Christopher F.},
	urldate = {2023-04-28},
	date = {2022},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ele.14123},
	keywords = {community ecology, computer vision, deep learning, high-resolution monitoring, remote sensing},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\TQ8F7YN3\\Besson et al. - 2022 - Towards the fully automated monitoring of ecologic.pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\EQVRLZBT\\ele.html:text/html},
}

@article{wilder_low-frequency_2023,
	title = {Low-Frequency Detection and Classification System ({LFDCS}) Reference Guide},
	url = {https://repository.library.noaa.gov/view/noaa/48671},
	doi = {10.25923/HSJ0-J449},
	author = {Wilder, Julianne},
	urldate = {2023-04-27},
	date = {2023},
	note = {Publisher: Northeast Fisheries Science Center (U.S.)},
}

@article{klinck_cetacean_2015,
	title = {Cetacean Studies on the Mariana Islands Range Complex in September-November 2014: Passive Acoustic Monitoring of Marine Mammals Using Gliders},
	author = {Klinck, H and Nieukirk, S L and Fregosi, S and Klinck, K and Mellinger, D K and Lastuka, S and Shilling, G B and Luby, J C},
	date = {2015},
	langid = {english},
	file = {Klinck et al. - 2015 - Cetacean Studies on the Mariana Islands Range Comp.pdf:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\Y488N2FW\\Klinck et al. - 2015 - Cetacean Studies on the Mariana Islands Range Comp.pdf:application/pdf},
}

@article{deutsch_glider_2020,
	title = {Glider performance analysis and intermediate-fidelity modelling of underwater vehicles},
	volume = {210},
	issn = {0029-8018},
	url = {https://www.sciencedirect.com/science/article/pii/S0029801820305758},
	doi = {10.1016/j.oceaneng.2020.107567},
	abstract = {This paper analyses the transit performance of state-of-the-art underwater vehicles and presents an intermediate-fidelity steady-state flight mechanics model for qualitative performance assessment of underwater vehicles. Focusing on the comparison of underwater gliders and propeller-driven {AUVs}, a simple glide metric is presented and the transit performance of the legacy underwater gliders Slocum, Spray and Seaglider as well as propeller-modified versions thereof is evaluated. The evaluation is based on various data sets from wind tunnel tests and Computational Fluid Dynamics ({CFD}) studies, and shows that for the respective hull shapes gliding locomotion proves more efficient in ideal conditions. However, biofouling conditions inflict a double penalty on glider performance, rendering gliders inferior to propeller-driven vehicles. The Slocum data set is used to validate a steady-state flight mechanics model for qualitative performance prediction. It is shown that even simplistic models based on semi-empirical and analytical expressions can be successfully used for design optimization through parametrization. Being computationally efficient, the model can be a useful tool for design engineers in early design phases. The model is used to evaluate the effects of wing span on gliding efficiency, indicating that the current design of the Slocum glider is near-optimal.},
	pages = {107567},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Deutsch, Clemens and Kuttenkeuler, Jakob and Melin, Tomas},
	urldate = {2023-04-27},
	date = {2020-08-15},
	langid = {english},
	keywords = {Autonomous Underwater Vehicle ({AUV}), Hydrodynamic modelling, Performance, Underwater glider},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\8X2KWA2U\\Deutsch et al. - 2020 - Glider performance analysis and intermediate-fidel.pdf:application/pdf},
}

@article{baumgartner_slocum_2020,
	title = {Slocum Gliders Provide Accurate Near Real-Time Estimates of Baleen Whale Presence From Human-Reviewed Passive Acoustic Detection Information},
	volume = {7},
	issn = {2296-7745},
	url = {https://www.frontiersin.org/articles/10.3389/fmars.2020.00100},
	abstract = {Mitigating the effects of human activities on marine mammals often depends on monitoring animal occurrence over long time scales, large spatial scales, and in real time. Passive acoustics, particularly from autonomous vehicles, is a promising approach to meeting this need. We have previously developed the capability to record, detect, classify, and transmit to shore information about the tonal sounds of baleen whales in near real time from long-endurance ocean gliders. We have recently developed a protocol by which a human analyst reviews this information to determine the presence of marine mammals, and the results of this review are automatically posted to a publicly accessible website, sent directly to interested parties via email or text, and made available to stakeholders via a number of public and private digital applications. We evaluated the performance of this system during two 3.75-month Slocum glider deployments in the southwestern Gulf of Maine during the spring seasons of 2015 and 2016. Near real-time detections of humpback, fin, sei, and North Atlantic right whales were compared to detections of these species from simultaneously recorded audio. Data from another 2016 glider deployment in the same area were also used to compare results between three different analysts to determine repeatability of results both among and within analysts. False detection (occurrence) rates on daily time scales were 0\% for all species. Daily missed detection rates ranged from 17 to 24\%. Agreement between two trained novice analysts and an experienced analyst was greater than 95\% for fin, sei, and right whales, while agreement was 83–89\% for humpback whales owing to the more subjective process for detecting this species. Our results indicate that the presence of baleen whales can be accurately determined using information about tonal sounds transmitted in near real-time from Slocum gliders. The system is being used operationally to monitor baleen whales in United States, Canadian, and Chilean waters, and has been particularly useful for monitoring the critically endangered North Atlantic right whale throughout the northwestern Atlantic Ocean.},
	journaltitle = {Frontiers in Marine Science},
	author = {Baumgartner, Mark F. and Bonnell, Julianne and Corkeron, Peter J. and Van Parijs, Sofie M. and Hotchkin, Cara and Hodges, Ben A. and Bort Thornton, Jacqueline and Mensi, Bryan L. and Bruner, Scott M.},
	urldate = {2023-04-26},
	date = {2020},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\Z5BGFZL5\\Baumgartner et al. - 2020 - Slocum Gliders Provide Accurate Near Real-Time Est.pdf:application/pdf},
}

@article{johnson_acoustic_2022,
	title = {Acoustic detection range of right whale upcalls identified in near-real time from a moored buoy and a Slocum glider},
	volume = {151},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/10.0010124},
	doi = {10.1121/10.0010124},
	abstract = {The goal of this study was to characterize the detection range of a near real-time baleen whale detection system, the digital acoustic monitoring instrument/low-frequency detection and classification system ({DMON}/{LFDCS}), equipped on a Slocum glider and a moored buoy. As a reference, a hydrophone array was deployed alongside the glider and buoy at a shallow-water site southwest of Martha's Vineyard (Massachusetts, {USA}) over a four-week period in spring 2017. A call-by-call comparison between North Atlantic right whale upcalls localized with the array (n = 541) and those detected by the glider or buoy was used to estimate the detection function for each {DMON}/{LFDCS} platform. The probability of detection was influenced by range, ambient noise level, platform depth, detection process, review protocol, and calling rate. The conservative analysis of near real-time pitch tracks suggested that, under typical conditions, a 0.33 probability of detection of a single call occurred at 6.2 km for the buoy and 8.6–13.4 km for the glider (depending on glider depth), while a 0.10 probability of detection of a single call occurred at 14.4 m for the buoy and 22.6–27.5 km for the glider. Probability of detection is predicted to increase substantially at all ranges if more than one call is available for detection.},
	pages = {2558--2575},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Johnson, Hansen D. and Taggart, Christopher T. and Newhall, Arthur E. and Lin, Ying-Tsong and Baumgartner, Mark F.},
	urldate = {2023-04-26},
	date = {2022-04-13},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\3N2DITJE\\Johnson et al. - 2022 - Acoustic detection range of right whale upcalls id.pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\T4L2VYKM\\Acoustic-detection-range-of-right-whale-upcalls.html:text/html},
}

@article{cauchy_gliders_2023,
	title = {Gliders for passive acoustic monitoring of the oceanic environment},
	volume = {4},
	issn = {2673-6187},
	url = {https://www.frontiersin.org/articles/10.3389/frsen.2023.1106533},
	abstract = {Ocean gliders are quiet, buoyancy-driven, long-endurance, profiling autonomous platforms. Gliders therefore possess unique advantages as platforms for Passive Acoustic Monitoring ({PAM}) of the marine environment. In this paper, we review available glider platforms and passive acoustic monitoring systems, and explore current and potential uses of passive acoustic monitoring-equipped gliders for the study of physical oceanography, biology, ecology and for regulatory purposes. We evaluate limiting factors for passive acoustic monitoring glider surveys, such as platform-generated and flow noise, weight, size and energy constraints, profiling ability and slow movement. Based on data from 34 passive acoustic monitoring glider missions, it was found that {\textless}13\% of the time spent at sea was unsuitable for passive acoustic monitoring measurements, either because of surface communications or glider manoeuvre, leaving the remainder available for subsequent analysis. To facilitate the broader use of passive acoustic monitoring gliders, we document best practices and include workarounds for the typical challenges of a passive acoustic monitoring glider mission. Three research priorities are also identified to improve future passive acoustic monitoring glider observations: 1) Technological developments to improve sensor integration and preserve glider endurance; 2) improved sampling methods and statistical analysis techniques to perform population density estimation from passive acoustic monitoring glider observations; and 3) calibration of the passive acoustic monitoring glider to record absolute noise levels, for anthropogenic noise monitoring. It is hoped this methodological review will assist glider users to broaden the observational capability of their instruments, and help researchers in related fields to deploy passive acoustic monitoring gliders in their studies.},
	journaltitle = {Frontiers in Remote Sensing},
	author = {Cauchy, Pierre and Heywood, Karen J. and Merchant, Nathan D. and Risch, Denise and Queste, Bastien Y. and Testor, Pierre},
	urldate = {2023-04-26},
	date = {2023},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\AMEC4RXI\\Cauchy et al. - 2023 - Gliders for passive acoustic monitoring of the oce.pdf:application/pdf},
}

@article{kowarski_near_2020,
	title = {Near real-time marine mammal monitoring from gliders: Practical challenges, system development, and management implications},
	volume = {148},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/10.0001811},
	doi = {10.1121/10.0001811},
	shorttitle = {Near real-time marine mammal monitoring from gliders},
	abstract = {In 2017, an endangered North Atlantic right whale mortality event in the Gulf of St. Lawrence, Canada, triggered the implementation of dynamic mitigation measures that required real-time information on whale distribution. Underwater glider-based acoustic monitoring offers a possible solution for collecting near real-time information but has many practical challenges including self-noise, energy restrictions, and computing capacity, as well as limited glider-to-shore data transfer bandwidth. This paper describes the development of a near real-time baleen whale acoustic monitoring glider system and its evaluation in the Gulf of St. Lawrence in 2018. Development focused on identifying and prioritizing important acoustic events and on sending contextual information to shore for human validation. The system performance was evaluated post-retrieval, then the trial was simulated using optimized parameters. Trial simulation evaluation revealed that the validated detections of right, fin, and blue whales produced by the system were all correct; the proportion of species occurrence missed varied depending on the timeframe considered. Glider-based near real-time monitoring can be an effective and reliable technique to inform dynamic mitigation strategies for species such as the North Atlantic right whale.},
	pages = {1215--1230},
	number = {3},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Kowarski, Katie A. and Gaudet, Briand J. and Cole, Arthur J. and Maxner, Emily E and Turner, Stephen P and Martin, S. Bruce and Johnson, Hansen D. and Moloney, John E.},
	urldate = {2023-04-26},
	date = {2020-09-08},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\ZX7TL347\\Kowarski et al. - 2020 - Near real-time marine mammal monitoring from glide.pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\BPEJXBTV\\Near-real-time-marine-mammal-monitoring-from.html:text/html},
}

@article{wood_illuminating_2021,
	title = {Illuminating the Nocturnal Habits of Owls with Emerging Tagging Technologies},
	volume = {45},
	issn = {2328-5540},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wsb.1156},
	doi = {10.1002/wsb.1156},
	abstract = {Owls play important cultural, ecological, and indicator roles throughout the world. Yet owls’ cryptic behavior has led to uncertainties about their basic ecology, including foraging, communication, and functional roles within the community, and potentially hindered the implementation of effective conservation measures. Here we demonstrate the potential for next-generation {GPS} tags capable of recording high-precision, minute-by-minute locations paired with other technologies to resolve some of these uncertainties. We combined high-precision {GPS} tagging data with infrared ({IR}) video recorded by arboreally-mounted cameras at 5 spotted owl (Strix occidentalis) nest sites in the Sierra Nevada, {USA} to provide a uniquely detailed examination of owl foraging patterns. Our approach allowed us to identify the precise time and location of 54 predation events and prey identity. We also used high-precision {GPS} tags with on-board audio recorders to map the vocal activity of 8 individuals by matching the time of vocalizations in the audio data to {GPS} locations recorded at one-minute intervals. The combined spatial and acoustic data revealed that nonbreeding males had the most widespread territorial vocal activity (i.e., producing 4-note territorial calls), while females provisioning fledglings displayed extensive nonterritorial vocal activity (i.e., producing many contact calls). Thus, the {GPS}-tag technologies we employed can provide opportunities to better understand owl foraging, communication, territoriality, and population dynamics. The methods we describe are time- and resource-intensive but can be paired with techniques that are more applicable at landscape scales, such as stable isotope analyses, {LiDAR}-based habitat analyses, and passive acoustic monitoring to link local processes to broad-scale ecological patterns. Therefore, our approach could be applied to many species whose behavior inhibits direct observation. © 2021 The Wildlife Society.},
	pages = {138--143},
	number = {1},
	journaltitle = {Wildlife Society Bulletin},
	author = {Wood, Connor M. and Zulla, Ceeanna and Whitmore, Sheila and Reid, Dana and Kramer, H. Anu and Keane, John J. and Sawyer, Sarah C. and Roberts, Kevin N. and Dotters, Brian P. and Klinck, Holger and Berigan, William and Gutiérrez, R. J. and Peery, M. Zachariah},
	urldate = {2023-04-24},
	date = {2021},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wsb.1156},
	keywords = {behavioral ecology, bioacoustics, communication, foraging ecology, {GPS} tag, infrared camera, passive acoustic monitoring, single-rope technique, Strix occidentalis},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\PCCCEGGM\\Wood et al. - 2021 - Illuminating the Nocturnal Habits of Owls with Eme.pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\SZKWGM6J\\wsb.html:text/html},
}

@article{rowe_rattlesnake_1986,
	title = {Rattlesnake Rattles and Burrowing Owl Hisses: A Case of Acoustic Batesian Mimicry},
	volume = {72},
	issn = {1439-0310},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0310.1986.tb00605.x},
	doi = {10.1111/j.1439-0310.1986.tb00605.x},
	shorttitle = {Rattlesnake Rattles and Burrowing Owl Hisses},
	abstract = {Burrowing owls nest and roost in ground squirrel burrows, a refuge frequently used by rattlesnakes. When cornered, burrowing owls produce a vocal hiss that has been suggested to mimic a rattlesnake's rattle. To test this hypothesis, we conducted an experiment using two populations of Douglas ground squirrels that differ in their evolutionary histories with rattlesnakes. Both squirrel populations were sympatric with burrowing owls. Squirrels from a population subjected to natural selection by rattlesnakes treated the owl hiss as cautiously as they did the rattle, and responded with greater caution to the rattle and hiss than to two control sounds. Squirrels from a rattlesnake-free area, however, were less systematic in differentiating among the rattle, the hiss, and the control treatments. Such variation between ground-squirrel populations provides evidence that the burrowing owl's defensive hiss currently functions as an acoustic Batesian mimic of a rattlesnake's rattle.},
	pages = {53--71},
	number = {1},
	journaltitle = {Ethology},
	author = {Rowe, Matthew P. and Coss, Richard G. and Owings, Donald H.},
	urldate = {2023-04-24},
	date = {1986},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1439-0310.1986.tb00605.x},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\M5VFA2DY\\Rowe et al. - 1986 - Rattlesnake Rattles and Burrowing Owl Hisses A Ca.pdf:application/pdf},
}

@article{hennessy_release_2022,
	title = {Release strategies and ecological factors influence mitigation translocation outcomes for burrowing owls: a comparative evaluation},
	volume = {25},
	issn = {1469-1795},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/acv.12767},
	doi = {10.1111/acv.12767},
	shorttitle = {Release strategies and ecological factors influence mitigation translocation outcomes for burrowing owls},
	abstract = {Mitigation translocations are increasing and if they are to fulfill their regulatory intent, the application of best-practice principles to release strategy and monitoring is required. With an investment of 3 years, we engaged with stakeholders, including developers, to improve outcomes from mitigation translocations of an at-risk species, the western burrowing owl Athene cunicularia hypugaea ({BUOW}). We evaluated the consequences of two primary translocation methods, displacement (i.e. exclusion from burrow) and translocation, against control owls, using a suite of success metrics focused on dispersal, survival and reproduction. We also tested the provision of visual and acoustic conspecific cues to dampen dispersal away from release sites. Within the displaced group, {BUOW} settled closer to the origin site if burrows were available nearby. Although translocated {BUOW} dispersed farther from the release site than displaced {BUOW}, this difference disappeared when conspecific cues were present. {BUOW} were 20 times more likely to settle at the release site when conspecifics or their cues were present. Translocating animals over longer distances ({\textgreater}17.5 km) reduced the incidence of {BUOW} returning to the origin site. When avoiding direct impacts to {BUOW} is not feasible, a determination of the most beneficial translocation method must be made, driven by site-specific conditions and the feasibility of implementing best management practices. The known costs of translocation to survival may be offset by long-term advantages such as the establishment of breeding populations inside protected areas. Mitigation translocations can benefit from carefully devised and tested hypotheses to determine what works and what does not; we advocate the increased use of evidence in mitigation translocation to guide management decisions and policies.},
	pages = {614--626},
	number = {5},
	journaltitle = {Animal Conservation},
	author = {Hennessy, S. M. and Wisinski, C. L. and Ronan, N. A. and Gregory, C. J. and Swaisgood, R. R. and Nordstrom, L. A.},
	urldate = {2023-04-24},
	date = {2022},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/acv.12767},
	keywords = {burrowing owl, conspecific cue, dispersal, mitigation, release strategy, relocation, translocation},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\V5XY8EIN\\Hennessy et al. - 2022 - Release strategies and ecological factors influenc.pdf:application/pdf},
}

@article{owings_rattling_2002,
	title = {The Rattling Sound of Rattlesnakes (Crotalus viridis) as a Communicative Resource for Ground Squirrels (Spermophilus beecheyi) and Burrowing Owls (Athene cunicularia )},
	volume = {116},
	doi = {10.1037/0735-7036.116.2.197},
	abstract = {Animal communication involves very dynamic processes that can generate new uses and functions for established communicative activities. In this article, the authors describe how an aposematic signal, the rattling sound of rattlesnakes (Crotalus viridis), has been exploited by 2 ecological associates of rattlesnakes: (a) California ground squirrels (Spermophilus beecheyi) use incidental acoustic cues in rattling sounds to assess the danger posed by the rattling snake, and (b) burrowing owls (Athene cunicularia) defend themselves against mammalian predators by mimicking the sound of rattling. The remarkable similarity between the burrowing owl's defensive hiss and the rattlesnake's rattling reflects both exaptation and adaptation. Such exploitation of the rattling sound has favored alternations in both the structure and the deployment of rattling by rattlesnakes.},
	pages = {197--205},
	journaltitle = {Journal of comparative psychology (Washington, D.C. : 1983)},
	shortjournal = {Journal of comparative psychology (Washington, D.C. : 1983)},
	author = {Owings, Donald and Rowe, Matthew and Rundus, Aaron},
	date = {2002-07-01},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\UNKU2YDC\\Owings et al. - 2002 - The Rattling Sound of Rattlesnakes (Crotalus virid.pdf:application/pdf},
}

@online{noauthor_using_nodate,
	title = {Using Acoustic Spatial Capture-Recapture to Estimate Owl Population Density and the Effects of Anthropogenic Factors in the Chattahoochee River National Recreation Area - {ProQuest}},
	url = {https://www.proquest.com/openview/ff03f9ba827382bb7c7992d443bcc3dc/1?cbl=18750&diss=y&pq-origsite=gscholar&parentSessionId=sbYV7%2Brr4cRKCd0TR%2FtGaxaiR4PbhQndIqObBcvxw1A%3D},
	abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the {ProQuest} Platform.},
	urldate = {2023-04-24},
	langid = {english},
	file = {Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\RWDGDM2S\\1.html:text/html},
}

@misc{stidsholt_echolocating_2022,
	title = {Echolocating bats prefer a high risk-high gain foraging strategy to increase prey profitability},
	rights = {© 2022, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2022.10.25.513681v1},
	doi = {10.1101/2022.10.25.513681},
	abstract = {Most bats catch nocturnal prey during active flight guided by echolocation but some species depart from this ancestral behaviour to capture ground prey using passive listening. Here, we explore the costs and benefits of these hunting transitions by combining high-resolution biologging data and {DNA} metabarcoding to quantify the relative contributions of aerial and ground prey to the total food intake of wild greater mouse-eared bats. We show that these bats use both foraging strategies with similar average nightly captures of 25 small, aerial insects and 30 large, ground-dwelling insects per bat, but with higher capture success in air (78 \% in air vs 30 \% on ground). However, owing to the 3 to 20 times heavier ground prey, 85 \% of the estimated nightly food acquisition comes from ground prey despite the 2.5 times higher failure rates. Further, we find that most bats use the same foraging strategy on a given night suggesting that bats adapt their hunting behaviour to weather and ground conditions. We conclude that prey switching matched to environmental dynamics plays a key role in covering the energy intake even in specialised predators.},
	publisher = {{bioRxiv}},
	author = {Stidsholt, Laura and Hubancheva, Antoniya and Greif, Stefan and Goerlitz, Holger R. and Johnson, Mark and Yovel, Yossi and Madsen, Peter T.},
	urldate = {2023-04-24},
	date = {2022-10-26},
	langid = {english},
	note = {Pages: 2022.10.25.513681
Section: New Results},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\N7IV7DNT\\Stidsholt et al. - 2022 - Echolocating bats prefer a high risk-high gain for.pdf:application/pdf},
}

@online{noauthor_acoustic_2017,
	title = {An Acoustic Arms Race},
	url = {https://www.americanscientist.org/article/an-acoustic-arms-race},
	abstract = {Bats and other animals use sound as a hunting tool--but their prey has also evolved ways to thwart detection.},
	titleaddon = {American Scientist},
	urldate = {2023-04-24},
	date = {2017-02-06},
	langid = {english},
	file = {Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\M9SKR4Q6\\an-acoustic-arms-race.html:text/html},
}

@article{noauthor_notitle_nodate-1,
}

@article{rankin_vocalizations_2007,
	title = {{VOCALIZATIONS} {OF} {THE} {SEI} {WHALE} \textit{{BALAENOPTERA} {BOREALIS}} {OFF} {THE} {HAWAIIAN} {ISLANDS}},
	volume = {16},
	issn = {0952-4622, 2165-0586},
	url = {http://www.tandfonline.com/doi/abs/10.1080/09524622.2007.9753572},
	doi = {10.1080/09524622.2007.9753572},
	abstract = {Little is known about the sounds produced by the Sei Whale Balaenoptera borealis and no recordings have been made in their presence in the Pacific Ocean. This research presents sounds recorded in the presence of Sei whales near the Hawaiian Islands in November, 2002. A total of 107 vocalizations, including two variations of low-frequency downswept calls, were measured. Two of these calls were sweeps from 100 Hz to 44 Hz, over 1.0 seconds. The second call type (n=105) consisted of lowfrequency calls which swept from 39 Hz to 21 Hz over 1.3 seconds. These calls are different from sounds attributed to Sei whales in the Atlantic and Southern Oceans, where recordings were made only in the summer months. These sounds are similar, however, to sounds attributed to fin whales in Hawaiian waters. Additional studies are needed in order to understand the spatial and temporal variation in the vocal repertoire of Sei and Fin whales in the Pacific Ocean.},
	pages = {137--145},
	number = {2},
	journaltitle = {Bioacoustics},
	shortjournal = {Bioacoustics},
	author = {Rankin, Shannon and Barlow, Jay},
	urldate = {2023-02-07},
	date = {2007-01},
	langid = {english},
	file = {Rankin and Barlow - 2007 - VOCALIZATIONS OF THE SEI WHALE BALAENOPTERA BOR.pdf:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\LILVIBZN\\Rankin and Barlow - 2007 - VOCALIZATIONS OF THE SEI WHALE BALAENOPTERA BOR.pdf:application/pdf},
}

@online{noauthor_acousticbased_nodate,
	title = {Acoustic‐based estimates of Cuvier's beaked whale (Ziphius cavirostris) density and abundance along the U.S. West Coast from drifting hydrophone recorders - Barlow - 2022 - Marine Mammal Science - Wiley Online Library},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/mms.12872},
	urldate = {2022-11-08},
	file = {Acoustic‐based estimates of Cuvier's beaked whale (Ziphius cavirostris) density and abundance along the U.S. West Coast from drifting hydrophone recorders - Barlow - 2022 - Marine Mammal Science - Wiley Online Library:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\XNPGB9L7\\mms.html:text/html},
}

@online{noauthor_acoustic_nodate,
	title = {Acoustic classification of dolphins in the California Current using whistles, echolocation clicks, and burst pulses - Rankin - 2017 - Marine Mammal Science - Wiley Online Library},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mms.12381},
	urldate = {2023-02-06},
	file = {Acoustic classification of dolphins in the California Current using whistles, echolocation clicks, and burst pulses - Rankin - 2017 - Marine Mammal Science - Wiley Online Library:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\A7XAEPVV\\mms.html:text/html},
}

@article{barlow_unique_2022,
	title = {Unique morphological and acoustic characteristics of beaked whales (Mesoplodon sp.) off the west coast of Baja California, Mexico},
	volume = {38},
	issn = {1748-7692},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mms.12853},
	doi = {10.1111/mms.12853},
	pages = {383--390},
	number = {1},
	journaltitle = {Marine Mammal Science},
	author = {Barlow, Jay and Cárdenas-Hinojosa, Gustavo and Henderson, E. Elizabeth and Breese, Dawn and López-Arzate, Diana and Hidalgo Pla, Eva and Taylor, Barbara L.},
	urldate = {2023-02-06},
	date = {2022},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/mms.12853},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\4452VHUI\\Barlow et al. - 2022 - Unique morphological and acoustic characteristics .pdf:application/pdf;Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\RU62YDEL\\Barlow et al. - 2022 - Unique morphological and acoustic characteristics .pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\KSC5TUGC\\mms.html:text/html;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\ZEREVVE5\\mms.html:text/html},
}

@software{archer_rfpermute_2022,
	title = {{rfPermute}: Estimate Permutation p-Values for Random Forest Importance Metrics},
	url = {https://cran.r-project.org/web/packages/rfPermute/index.html},
	version = {R package version 2.5.1},
	author = {Archer, Frederick},
	date = {2022},
}

@report{yano_cetacean_2018,
	title = {Cetacean and seabird data collected during the Hawaiian islands cetacean and ecosystem assessment survey ({HICEAS}), July–December 2017},
	url = {https://repository.library.noaa.gov/view/noaa/18660},
	number = {{OCS} Study {BOEM} 2018-044},
	institution = {Bureau of Ocean Energy Management},
	type = {{OCS} Study {BOEM}},
	author = {Yano, Kymberly M. and Oleson, Erin M. and Keating, Jennifer L. and Ballance, Lisa and Hill, Marie C. and Bradford, Amanda and Allen, Ann N. and Joyce, Trevor W. and Moore, Jeffrey E. and Henry, Annette E.},
	date = {2018},
}

@article{bittle_review_2013,
	title = {A review of current marine mammal detection and classification algorithms for use in automated passive acoustic monitoring.},
	volume = {2013},
	abstract = {The detection and classification of marine mammal vocalisations is an important component in noise mitigation strategies and in the tracking of animals for research purposes. These complex vocalisations span a broad range of frequencies with differences between and within species, and with temporal and geographical variations adding further complexity. Passive Acoustic Monitoring ({PAM}) systems can be deployed for long periods and can collect large volumes of data, becoming impractical for human operators to manually process due to the significant effort required. Many signal processing algorithms to automate this process have been produced with mixed results. Some are focused on the identification of single species while others handle a variety. No single algorithm is ideal for detecting and classifying all species concurrently, so any automated system requires a suite of these algorithms. A number of these algorithms are summarised here as part of an initial step in the construction of a {PAM} system incorporating real-time detection and classification.},
	pages = {8},
	journaltitle = {Proceedings of Acoustics},
	author = {Bittle, Michael and Duncan, Alec},
	date = {2013},
	langid = {english},
	file = {Bittle and Duncan - 2013 - A review of current marine mammal detection and cl.pdf:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\BETFBU5H\\Bittle and Duncan - 2013 - A review of current marine mammal detection and cl.pdf:application/pdf},
}

@report{keating_summary_2013,
	title = {Summary of {PAMGuard} beaked whale click detectors and classifiers used during the 2012 Southern California Behavioral Response Study},
	pages = {14},
	number = {{NOAA}-{TM}-{NMFS}-{SWFSC}-517},
	type = {{NOAA} Tech Memo},
	author = {Keating, Jennifer L. and Barlow, Jay},
	date = {2013},
}

@report{keating_passive_2018,
	title = {Passive acoustics survey of cetacean abundance levels ({PASCAL}-2016) final report},
	url = {https://www.boem.gov/sites/default/files/environmental-stewardship/Environmental-Studies/Pacific-Region/Studies/BOEM-2018-025.pdf},
	pages = {22},
	number = {25},
	institution = {{US} Department of the Interior, Bureau of Ocean Energy Management},
	type = {{OCS} Study {BOEM}},
	author = {Keating, Jennifer and Barlow, Jay and Griffiths, Emily T. and Moore, Jeffrey E.},
	date = {2018},
}

@unpublished{rankin_banter_2021,
	title = {{BANTER}: A User's Guide to Acoustic Classification},
	url = {https://taikisan21.github.io/PAMpal/banterGuide.html},
	author = {Rankin, Shannon and Archer, Frederick},
	date = {2021},
}

@software{archer_banter_2022,
	title = {Banter: {BioAcoustic} {eveNT} {classifiER}},
	url = {https://cran.r-project.org/web/packages/banter/index.html},
	version = {R package version 0.9.5},
	author = {Archer, Frederick},
	date = {2022},
}

@software{sakai_pampal_2021,
	title = {{PAMpal}: Load and Process Passive Acoustic Data},
	url = {https://cran.r-project.org/web/packages/PAMpal/index.html},
	version = {R package version 0.17.0},
	author = {Sakai, Taiki},
	date = {2021},
}

@article{rankin_acoustic_2017,
	title = {Acoustic classification of dolphins in the California Current using whistles, echolocation clicks, and burst pulses},
	volume = {2},
	issn = {0824-0469, 1748-7692},
	url = {https://www.infona.pl//resource/bwmeta1.element.wiley-mms-v-33-i-2-mms12381},
	doi = {10.1111/mms.12381},
	abstract = {{\textless}p{\textgreater}Passive acoustic monitoring of dolphins is limited by our ability to classify calls to species. Significant overlap in call characteristics among many species, combined with a wide range of call types and acoustic behavior, makes classification of calls to species challenging. Here, we introduce {\textless}span{\textgreater}{BANTER}{\textless}/span{\textgreater}, a compound acoustic classification method for dolphins that utilizes information from all call types produced by dolphins rather than a single call type, as has been typical for acoustic classifiers. Output from the passive acoustic monitoring software, {\textless}span{\textgreater}{PAMG}{\textless}/span{\textgreater}uard, was used to create independent classifiers for whistles, echolocation clicks, and burst pulses, which were then merged into a final, compound classifier for each species. Classifiers for five species found in the California Current ecosystem were trained and tested using 153 single‐species acoustic events recorded during a 4.5 mo combined visual and acoustic shipboard cetacean survey off the west coast of the United States. Correct classification scores for individual species ranged from 71\% to 92\%, with an overall correct classification score of 84\% for all five species. The conceptual framework of this approach easily lends itself to other species and study areas as well as to noncetacean taxa.{\textless}/p{\textgreater}},
	pages = {520--540},
	number = {33},
	journaltitle = {Marine Mammal Science},
	author = {Rankin, Shannon and Archer, Frederick and Keating, Jennifer L. and Oswald, Julie N. and Oswald, Michael and Curtis, Alex and Barlow, Jay},
	urldate = {2023-02-06},
	date = {2017-04-13},
	file = {Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\6XZ2IKRJ\\bwmeta1.element.html:text/html},
}

@article{parijs_management_2009,
	title = {Management and research applications of real-time and archival passive acoustic sensors over varying temporal and spatial scales},
	volume = {395},
	issn = {0171-8630, 1616-1599},
	url = {https://www.int-res.com/abstracts/meps/v395/p21-36/},
	doi = {10.3354/meps08123},
	abstract = {Defining the appropriate scale over which to conduct a study in the marine environment is critical to achieving appropriate scientific, management, mitigation and conservation objectives. This paper focuses on applications of passive acoustic technologies over a range of spatial and temporal scales. It is divided into sections dealing with archival and real-time passive acoustic sensor applications. Each section assesses the principles behind using the respective technology and provides recent examples of research and management applications for marine mammals and fish. The section on archival sensors highlights the need for continued development of automated acoustic detectors to assess large data sets. Case studies are presented of detectors developed for determining seasonal occurrence and distribution of haddock sounds and humpback whale vocalizations. Also presented are studies of other applications using archival sensors: tracking singing humpback whales in Brazil, using vocalizations to assess the reproductive strategies of Arctic bearded seals and assessing regional variability in call patterns for North Atlantic right whales. The section on real-time passive acoustic sensors focuses on real-time buoys and towed arrays. Case studies presented include a real-time buoy system used for monitoring endangered North Atlantic right whales and a stationary autonomous array providing real-time access to Antarctic acoustic data. The value of using towed arrays for real-time applications is also assessed, and a case study is provided on the use of towed arrays to improve abundance estimates of North Pacific cetaceans and to better understand vocalization behaviors.},
	pages = {21--36},
	journaltitle = {Marine Ecology Progress Series},
	author = {Parijs, Sofie M. Van and Clark, Chris W. and Sousa-Lima, Renata S. and Parks, Susan E. and Rankin, Shannon and Risch, Denise and Opzeeland, Ilse C. Van},
	urldate = {2022-11-08},
	date = {2009-12-03},
	langid = {english},
	keywords = {Archival arrays, Automated detection, Fish, Localization, Marine mammals, Mesoscale, Passive acoustics, Real-time buoys, Towed arrays},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\WTMBCQ2D\\Parijs et al. - 2009 - Management and research applications of real-time .pdf:application/pdf},
}

@article{rankin_source_2005,
	title = {Source of the North Pacific “boing” sound attributed to minke whales},
	volume = {118},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.2046747},
	doi = {10.1121/1.2046747},
	pages = {3346--3351},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Rankin, Shannon and Barlow, Jay},
	urldate = {2023-02-06},
	date = {2005-11},
	note = {Publisher: Acoustical Society of America},
}

@article{barlow_acoustic-based_2022,
	title = {Acoustic-based estimates of Cuvier's beaked whale (Ziphius cavirostris) density and abundance along the U.S. West Coast from drifting hydrophone recorders},
	volume = {38},
	issn = {1748-7692},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mms.12872},
	doi = {10.1111/mms.12872},
	abstract = {An acoustic survey of Cuvier's beaked whales (Ziphius cavirostris) was conducted off the U.S. West Coast in August and September 2016 using drifting recorder systems with a vertical array of two hydrophones at a depth of 110 m. Recorders were deployed 22 times to representatively cover a 1,058,000 km2 study area from the shelf break to 556 km offshore. Vertical angles to echolocation pulses were measured using the signal time-difference-of-arrival on the two hydrophones. Echolocation pulses of Cuvier's beaked whales were identified from their arrival angles (always from below the array) and unique acoustic characteristics. The density and abundance of Cuvier's beaked whales were estimated using a group-based point-transect analysis with 2 min time snapshots. The area effectively surveyed was estimated using a maximum simulated likelihood approach to fit the observed distribution of signal arrival angles. The acoustic availability of whales during their dive cycle was estimated from the duration of acoustic encounters using a mark-recapture approach. Overall, Cuvier's beaked whales were present during 0.60\% of snapshots, and their estimated average density is 5.12 animals per 1,000 km2 ({CV} = 0.27). Their estimated abundance in the study area is 5,454 individuals (95\% credibility intervals: 3,151 to 8,907).},
	pages = {517--538},
	number = {2},
	journaltitle = {Marine Mammal Science},
	author = {Barlow, Jay and Moore, Jeffrey E. and {McCullough}, Jennifer L. K. and Griffiths, Emily T.},
	urldate = {2023-02-06},
	date = {2022},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/mms.12872},
	keywords = {abundance estimation, acoustic survey, Cuvier's beaked whale, drifting buoy recorder, echolocation, point-transect, vertical hydrophone array, Ziphius cavirostris},
	file = {Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\6H5DRQ25\\mms.html:text/html},
}

@article{baumann-pickering_echolocation_2010,
	title = {Echolocation signals of a beaked whale at Palmyra Atoll},
	volume = {127},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.3409478},
	doi = {10.1121/1.3409478},
	pages = {3790--3799},
	number = {6},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Baumann-Pickering, Simone and Wiggins, Sean M. and Roth, Ethan H. and Roch, Marie A. and Schnitzler, Hans-Ulrich and Hildebrand, John A.},
	urldate = {2023-02-06},
	date = {2010-06},
	note = {Publisher: Acoustical Society of America},
}

@article{cholewiak_description_2013,
	title = {Description of sounds associated with Sowerby's beaked whales (Mesoplodon bidens) in the western North Atlantic Ocean},
	volume = {134},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.4823843},
	doi = {10.1121/1.4823843},
	pages = {3905--3912},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Cholewiak, Danielle and Baumann-Pickering, Simone and Van Parijs, Sofie},
	urldate = {2023-02-06},
	date = {2013-11},
	note = {Publisher: Acoustical Society of America},
}

@article{simonis_co-occurrence_2020,
	title = {Co-occurrence of beaked whale strandings and naval sonar in the Mariana Islands, Western Pacific},
	volume = {287},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rspb.2020.0070},
	doi = {10.1098/rspb.2020.0070},
	abstract = {Mid-frequency active sonar ({MFAS}), used for antisubmarine warfare ({ASW}), has been associated with multiple beaked whale ({BW}) mass stranding events. Multinational naval {ASW} exercises have used {MFAS} offshore of the Mariana Archipelago semi-annually since 2006. We report {BW} and {MFAS} acoustic activity near the islands of Saipan and Tinian from March 2010 to November 2014. Signals from Cuvier's (Ziphius cavirostris) and Blainville's beaked whales (Mesoplodon densirostris), and a third unidentified {BW} species, were detected throughout the recording period. Both recorders documented {MFAS} on 21 August 2011 before two Cuvier's beaked whales stranded on 22–23 August 2011. We compared the history of known naval operations and {BW} strandings from the Mariana Archipelago to consider potential threats to {BW} populations. Eight {BW} stranding events between June 2006 and January 2019 each included one to three animals. Half of these strandings occurred during or within 6 days after naval activities, and this co-occurrence is highly significant. We highlight strandings of individual {BWs} can be associated with {ASW}, and emphasize the value of ongoing passive acoustic monitoring, especially for beaked whales that are difficult to visually detect at sea. We strongly recommend more visual monitoring efforts, at sea and along coastlines, for stranded cetaceans before, during and after naval exercises.},
	pages = {20200070},
	number = {1921},
	journaltitle = {Proceedings of the Royal Society B: Biological Sciences},
	author = {Simonis, Anne E. and Brownell, Robert L. and Thayre, Bruce J. and Trickey, Jennifer S. and Oleson, Erin M. and Huntington, Roderick and Baumann-Pickering, Simone},
	urldate = {2023-02-06},
	date = {2020-02-19},
	note = {Publisher: Royal Society},
	keywords = {beaked whales, mid-frequency active sonar, Navy sonar, stranding event, Ziphiidae},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\8PYE7RUG\\Simonis et al. - 2020 - Co-occurrence of beaked whale strandings and naval.pdf:application/pdf},
}

@article{noauthor_notitle_nodate-2,
}

@article{frouin-mouy_acoustic_2022,
	title = {Acoustic and visual cetacean surveys reveal year-round spatial and temporal distributions for multiple species in northern British Columbia, Canada},
	volume = {12},
	rights = {2022 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-022-22069-4},
	doi = {10.1038/s41598-022-22069-4},
	abstract = {Cetaceans spend most of their time below the surface of the sea, highlighting the importance of passive acoustic monitoring as a tool to facilitate understanding and mapping their year-round spatial and temporal distributions. To increase our limited knowledge of cetacean acoustic detection patterns for the east and west coasts of Gwaii Haanas, a remote protected area on Haida Gwaii, {BC}, Canada, acoustic datasets recorded off {SG}̱ang Gwaay (Sep 2009–May 2011), Gowgaia Slope (Jul 2017–Jul 2019), and Ramsay Island (Aug 2018–Aug 2019) were analyzed. Comparing overlapping periods of visual surveys and acoustic monitoring confirmed presence of 12 cetacean species/species groups within the study region. Seasonal patterns were identified for blue, fin, humpback, grey and sperm whale acoustic signals. Killer whale and delphinid acoustic signals occurred year-round on both coasts of Haida Gwaii and showed strong diel variation. Cuvier’s, Baird’s, beaked whale and porpoise clicks, were identified in high-frequency recordings on the west coast. Correlations between environmental factors, chlorophyll-a and sea surface temperature, and cetacean acoustic occurrence off Gwaii Haanas were also examined. This study is the first to acoustically monitor Gwaii Haanas waters for an extended continuous period and therefore serves as a baseline from which to monitor future changes.},
	pages = {19272},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Frouin-Mouy, Héloïse and Mouy, Xavier and Pilkington, James and Küsel, Elizabeth and Nichol, Linda and Doniol-Valcroze, Thomas and Lee, Lynn},
	urldate = {2022-11-16},
	date = {2022-11-10},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Animal migration, Ecology, Marine biology},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\HMSKM4DG\\Frouin-Mouy et al. - 2022 - Acoustic and visual cetacean surveys reveal year-r.pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\XFVF8W8M\\s41598-022-22069-4.html:text/html},
}

@article{cerchio_mid-frequency_nodate,
	title = {Mid-frequency song and low-frequency calls of sei whales in the Falkland Islands},
	volume = {9},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.220738},
	doi = {10.1098/rsos.220738},
	abstract = {Although sei whales (Balaenoptera borealis) are distributed throughout the globe, their behaviour and vocal repertoire are poorly described. We used passive acoustic monitoring to describe the vocal behaviour of sei whales in the Falkland Islands, between December 2018 and April 2019. We isolated more than 2000 low-frequency calls for manual classification, of which 510 calls with high signal-to-noise ratio were quantitatively measured. Five categories of stereotyped call types in the 15–230 Hz range were described, some with multiple subcategories. These included some similar to previously described calls (e.g. downsweeps), but others that were novel in acoustic structure and frequency band. In the mid-frequency range, we documented a highly stereotyped, hierarchically structured and rhythmically repetitive song display. Songs were arranged in phrases with a structure composed of repetitive sub-phrases, and a diverse variety of sounds in the 1–5 {kHz} range. Singing commenced in late February, despite the presence of whales and calls since early December, and continued through April. These acoustic properties and behavioural characteristics indicate that this is likely a male breeding display similar to songs and singing of other balaenopterids. This is the first detailed description of a song display for sei whales, highlighting the importance of the Falkland Islands.},
	pages = {220738},
	number = {11},
	journaltitle = {Royal Society Open Science},
	author = {Cerchio, Salvatore and Weir, Caroline R.},
	urldate = {2022-11-10},
	keywords = {passive acoustic monitoring, Balaenoptera borealis, low-frequency calls, singing behaviour, song display},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\SDWJDKA9\\Cerchio and Weir - Mid-frequency song and low-frequency calls of sei .pdf:application/pdf},
}

@article{simonis_lunar_2017,
	title = {Lunar cycles affect common dolphin Delphinus delphis foraging in the Southern California Bight},
	volume = {577},
	issn = {0171-8630, 1616-1599},
	url = {https://www.int-res.com/abstracts/meps/v577/p221-235/},
	doi = {10.3354/meps12247},
	abstract = {In the Southern California Bight, the common dolphin Delphinus delphis is the most abundant dolphin species and preys upon small pelagic fish, mesopelagic fish, and cephalopods. Mesopelagic fish and many cephalopods are available throughout the year, and they form deep scattering layers, some of which characteristically undergo strong diel vertical migrations. The extent of vertical migration depends on the degree of sea surface solar and lunar illumination. At their daytime depth, mesopelagic prey are beyond the range of shallow-diving dolphins. Autonomous acoustic recorders were used to monitor dolphin echolocation at 2 offshore recording locations from 2009 to 2014. Manual and automated classification techniques were used to identify periods of high echolocation activity, indicative of common dolphin foraging. Clear lunar patterns existed in cool months, when echolocation activity was highest during the darkest periods of the night and lunar month, indicating times when dolphins were foraging, possibly on mesopelagic prey. Echolocation was more abundant during warm months, but diel and lunar patterns in echolocation were weaker. Generalized additive mixed models show that the observed patterns in echolocation activity are correlated with lunar day and position of the moon in the night sky. Seasonal patterns may represent geographic shifts in common dolphin populations, shoaling scattering layers, or prey switching behavior during the warm months, whereby dolphins target small pelagic fish not associated with the deep scattering layers. Overall, dolphin foraging activity declined from 2009 to 2014 during warm months, which may be related to a declining abundance of small pelagic fish.},
	pages = {221--235},
	journaltitle = {Marine Ecology Progress Series},
	author = {Simonis, Anne E. and Roch, Marie A. and Bailey, Barbara and Barlow, Jay and Clemesha, Rachel E. S. and Iacobellis, Sam and Hildebrand, John A. and Baumann-Pickering, Simone},
	urldate = {2022-11-10},
	date = {2017-08-18},
	langid = {english},
	keywords = {Deep scattering layers, Dolphins, Echolocation, Foraging, Lunar cycle, Mesopelagic},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\ZDCIRAK2\\Simonis et al. - 2017 - Lunar cycles affect common dolphin Delphinus delph.pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\48Z87WVT\\Simonis et al. - 2017 - Lunar cycles affect common dolphin Delphinus delph.html:text/html},
}

@online{noauthor_inter_nodate,
	title = {Inter Research » {MEPS} » v577 » p221-235},
	url = {https://www.int-res.com/abstracts/meps/v577/p221-235/},
	urldate = {2022-11-10},
}

@article{zahn_acoustic_2021,
	title = {Acoustic differentiation and classification of wild belugas and narwhals using echolocation clicks},
	volume = {11},
	rights = {2021 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-01441-w},
	doi = {10.1038/s41598-021-01441-w},
	abstract = {Belugas (Delphinapterus leucas) and narwhals (Monodon monoceros) are highly social Arctic toothed whales with large vocal repertoires and similar acoustic profiles. Passive Acoustic Monitoring ({PAM}) that uses multiple hydrophones over large spatiotemporal scales has been a primary method to study their populations, particularly in response to rapid climate change and increasing underwater noise. This study marks the first acoustic comparison between wild belugas and narwhals from the same location and reveals that they can be acoustically differentiated and classified solely by echolocation clicks. Acoustic recordings were made in the pack ice of Baffin Bay, West Greenland, during 2013. Multivariate analyses and Random Forests classification models were applied to eighty-one single-species acoustic events comprised of numerous echolocation clicks. Results demonstrate a significant difference between species’ acoustic parameters where beluga echolocation was distinguished by higher frequency content, evidenced by higher peak frequencies, center frequencies, and frequency minimums and maximums. Spectral peaks, troughs, and center frequencies for beluga clicks were generally {\textgreater} 60 {kHz} and narwhal clicks {\textless} 60 {kHz} with overlap between 40–60 {kHz}. Classification model predictive performance was strong with an overall correct classification rate of 97.5\% for the best model. The most important predictors for species assignment were defined by peaks and notches in frequency spectra. Our results provide strong support for the use of echolocation in {PAM} efforts to differentiate belugas and narwhals acoustically.},
	pages = {22141},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Zahn, Marie J. and Rankin, Shannon and {McCullough}, Jennifer L. K. and Koblitz, Jens C. and Archer, Frederick and Rasmussen, Marianne H. and Laidre, Kristin L.},
	urldate = {2022-11-08},
	date = {2021-11-12},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Marine mammals, Conservation biology, Ecological modelling},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\HXLAXFAZ\\Zahn et al. - 2021 - Acoustic differentiation and classification of wil.pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\SMXXEF2M\\s41598-021-01441-w.html:text/html},
}

@online{noauthor_co-occurrence_nodate,
	title = {Co-occurrence of beaked whale strandings and naval sonar in the Mariana Islands, Western Pacific {\textbar} Proceedings of the Royal Society B: Biological Sciences},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspb.2020.0070},
	urldate = {2022-11-08},
	file = {Co-occurrence of beaked whale strandings and naval sonar in the Mariana Islands, Western Pacific | Proceedings of the Royal Society B\: Biological Sciences:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\CVG5QJ7N\\rspb.2020.html:text/html},
}

@article{soldevilla_classification_2008,
	title = {Classification of Risso’s and Pacific white-sided dolphins using spectral properties of echolocation clicks},
	volume = {124},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/10.1121/1.2932059},
	doi = {10.1121/1.2932059},
	pages = {609--624},
	number = {1},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Soldevilla, Melissa S. and Henderson, E. Elizabeth and Campbell, Gregory S. and Wiggins, Sean M. and Hildebrand, John A. and Roch, Marie A.},
	urldate = {2022-11-08},
	date = {2008-07},
	note = {Publisher: Acoustical Society of America},
	file = {Full Text:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\DPV7X9SI\\Soldevilla et al. - 2008 - Classification of Risso’s and Pacific white-sided .pdf:application/pdf},
}

@online{noauthor_source_nodate,
	title = {Source of the North Pacific “boing” sound attributed to minke whales: The Journal of the Acoustical Society of America: Vol 118, No 5},
	url = {https://asa.scitation.org/doi/10.1121/1.2046747},
	urldate = {2022-11-08},
	file = {Source of the North Pacific “boing” sound attributed to minke whales\: The Journal of the Acoustical Society of America\: Vol 118, No 5:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\LUDLU78H\\1.html:text/html},
}

@article{team_r_2013,
	title = {R: A language and environment for statistical computing},
	shorttitle = {R},
	author = {Team, R. Core},
	date = {2013},
	note = {Publisher: Vienna, Austria},
}

@article{mcdonald_acoustic_2009,
	title = {An acoustic survey of beaked whales at Cross Seamount near Hawaii},
	volume = {125},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/10.1121/1.3050317},
	doi = {10.1121/1.3050317},
	pages = {624--627},
	number = {2},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {{McDonald}, Mark A. and Hildebrand, John A. and Wiggins, Sean M. and Johnston, David W. and Polovina, Jeffrey J.},
	urldate = {2022-11-08},
	date = {2009-02},
	note = {Publisher: Acoustical Society of America},
	file = {Full Text:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\CCFVYKQ5\\McDonald et al. - 2009 - An acoustic survey of beaked whales at Cross Seamo.pdf:application/pdf},
}

@incollection{macleod_beaked_2018,
	title = {Beaked Whales, Overview},
	isbn = {978-0-12-804327-1},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128043271000625},
	abstract = {With 22 members, the beaked whales are the second largest family of cetaceans after the family Delphinidae. They are medium-sized cetaceans with spindle-shaped bodies and a dorsal fin set two-thirds of the way along the body, and adult size ranges from just under 4m to about 12m. The beaked whales are among the deepest and longest diving of all marine mammals, and they can dive to depths of several thousand meters and remain under water for an hour or more to feed on deep water squid, fish, and to a lesser extent crustaceans. Adult males of most species have a single pair of tusks used in aggressive male–male combat, and in general, juveniles and females are functionally toothless. There are currently 22 recognized species in six different genera.},
	pages = {80--83},
	booktitle = {Encyclopedia of Marine Mammals (Third Edition)},
	publisher = {Academic Press},
	author = {{MacLeod}, Colin D.},
	editor = {Würsig, Bernd and Thewissen, J. G. M. and Kovacs, Kit M.},
	urldate = {2022-11-08},
	date = {2018-01-01},
	langid = {english},
	doi = {10.1016/B978-0-12-804327-1.00062-5},
	keywords = {Ziphiidae, Beaked whales, ecology},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\RWAABAB8\\B9780128043271000625.html:text/html},
}

@article{deangelis_description_2018,
	title = {A description of echolocation clicks recorded in the presence of True's beaked whale (Mesoplodon mirus)},
	volume = {144},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/10.1121/1.5067379},
	doi = {10.1121/1.5067379},
	pages = {2691--2700},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {{DeAngelis}, Annamaria Izzi and Stanistreet, Joy E. and Baumann-Pickering, Simone and Cholewiak, Danielle M.},
	urldate = {2022-11-08},
	date = {2018-11},
	note = {Publisher: Acoustical Society of America},
}

@online{noauthor_echolocation_nodate,
	title = {Echolocation signals of a beaked whale at Palmyra Atoll: The Journal of the Acoustical Society of America: Vol 127, No 6},
	url = {https://asa.scitation.org/doi/10.1121/1.3409478},
	urldate = {2022-11-08},
	file = {Echolocation signals of a beaked whale at Palmyra Atoll\: The Journal of the Acoustical Society of America\: Vol 127, No 6:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\SJ5V59JY\\1.html:text/html},
}

@article{baumann-pickering_species-specific_2013,
	title = {Species-specific beaked whale echolocation signals},
	volume = {134},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.4817832},
	doi = {10.1121/1.4817832},
	pages = {2293--2301},
	number = {3},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Baumann-Pickering, Simone and {McDonald}, Mark A. and Simonis, Anne E. and Solsona Berga, Alba and Merkens, Karlina P. B. and Oleson, Erin M. and Roch, Marie A. and Wiggins, Sean M. and Rankin, Shannon and Yack, Tina M. and Hildebrand, John A.},
	urldate = {2022-11-08},
	date = {2013-09},
	note = {Publisher: Acoustical Society of America},
}

@article{baumann-pickering_spatio-temporal_2014,
	title = {Spatio-Temporal Patterns of Beaked Whale Echolocation Signals in the North Pacific},
	volume = {9},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0086072},
	doi = {10.1371/journal.pone.0086072},
	abstract = {At least ten species of beaked whales inhabit the North Pacific, but little is known about their abundance, ecology, and behavior, as they are elusive and difficult to distinguish visually at sea. Six of these species produce known species-specific frequency modulated ({FM}) echolocation pulses: Baird’s, Blainville’s, Cuvier’s, Deraniyagala’s, Longman’s, and Stejneger’s beaked whales. Additionally, one described {FM} pulse ({BWC}) from Cross Seamount, Hawai’i, and three unknown {FM} pulse types ({BW}40, {BW}43, {BW}70) have been identified from almost 11 cumulative years of autonomous recordings at 24 sites throughout the North Pacific. Most sites had a dominant {FM} pulse type with other types being either absent or limited. There was not a strong seasonal influence on the occurrence of these signals at any site, but longer time series may reveal smaller, consistent fluctuations. Only the species producing {BWC} signals, detected throughout the Pacific Islands region, consistently showed a diel cycle with nocturnal foraging. By comparing stranding and sighting information with acoustic findings, we hypothesize that {BWC} signals are produced by ginkgo-toothed beaked whales. {BW}43 signal encounters were restricted to Southern California and may be produced by Perrin’s beaked whale, known only from Californian waters. {BW}70 signals were detected in the southern Gulf of California, which is prime habitat for Pygmy beaked whales. Hubb’s beaked whale may have produced the {BW}40 signals encountered off central and southern California; however, these signals were also recorded off Pearl and Hermes Reef and Wake Atoll, which are well south of their known range.},
	pages = {e86072},
	number = {1},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Baumann-Pickering, Simone and Roch, Marie A. and Jr, Robert L. Brownell and Simonis, Anne E. and {McDonald}, Mark A. and Solsona-Berga, Alba and Oleson, Erin M. and Wiggins, Sean M. and Hildebrand, John A.},
	urldate = {2022-11-08},
	date = {2014-01-22},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Acoustics, Echolocation, Beaked whales, Acoustic signals, Atolls, Bioacoustics, Islands, Reefs},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\2PNAFT3L\\Baumann-Pickering et al. - 2014 - Spatio-Temporal Patterns of Beaked Whale Echolocat.pdf:application/pdf},
}

@online{noauthor_description_nodate,
	title = {Description of sounds associated with Sowerby's beaked whales (Mesoplodon bidens) in the western North Atlantic Ocean: The Journal of the Acoustical Society of America: Vol 134, No 5},
	url = {https://asa.scitation.org/doi/10.1121/1.4823843},
	urldate = {2022-11-08},
	file = {Description of sounds associated with Sowerby's beaked whales (Mesoplodon bidens) in the western North Atlantic Ocean\: The Journal of the Acoustical Society of America\: Vol 134, No 5:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\MDGYN5Z6\\1.html:text/html},
}

@article{barlow_acoustic_2021,
	title = {Acoustic detection range and population density of Cuvier's beaked whales estimated from near-surface hydrophones},
	volume = {149},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/10.0002881},
	doi = {10.1121/10.0002881},
	abstract = {The population density of Cuvier's beaked whales is estimated acoustically with drifting near-surface hydrophone recorders in the Catalina Basin. Three empirical approaches (trial-based, distance-sampling, and spatially explicit capture-recapture) are used to estimate the probability of detecting the echolocation pulses as a function of range. These detection functions are used with two point-transect methods (snapshot and dive-cue) to estimate density. Measurement errors result in a small range of density estimates (3.9–5.4 whales per 1000 km2). Use of multiple approaches and methods allows comparison of the required information and assumptions of each. The distance-sampling approach with snapshot-based density estimates has the most stringent assumptions but would be the easiest to implement for large scale surveys of beaked whale density. Alternative approaches to estimating detection functions help validate this approach. The dive cue method of density estimation has promise, but additional work is needed to understand the potential bias caused by animal movement during a dive. Empirical methods are a viable alternative to the theoretical acoustic modeling approaches that have been used previously to estimate beaked whale density.},
	pages = {111--125},
	number = {1},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Barlow, Jay and Fregosi, Selene and Thomas, Len and Harris, Danielle and Griffiths, Emily T.},
	urldate = {2023-09-22},
	date = {2021-01-05},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\IRXALYVZ\\Barlow et al. - 2021 - Acoustic detection range and population density of.pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\ZK8PQA8T\\610260.html:text/html},
}

@article{vanparijs_establishing_2023,
	title = {Establishing baselines for predicting change in ambient sound metrics, marine mammal, and vessel occurrence within a {US} offshore wind energy area},
	issn = {1054-3139},
	url = {https://doi.org/10.1093/icesjms/fsad148},
	doi = {10.1093/icesjms/fsad148},
	abstract = {Evaluating potential impacts on marine animals or increased sound levels resulting from offshore wind energy construction requires the establishment of baseline data records from which to draw inference. This study provides 2 years of baseline data on cetacean species’ presence, vessel activity, and ambient sound levels in the southern New England wind energy area. With eight species/families present in the area for at least 9 months of the year, this area represents an important habitat for cetaceans. Most species showed seasonality, with peak daily presence in winter (harbour porpoise, North Atlantic right, fin, and humpback whales), summer (sperm whales), spring (sei whales), or spring and fall/autumn (minke whales). Delphinids were continuously present and blue whales present only in January. The endangered North Atlantic right whales were present year round with high presence in October through April. Daily vessel presence showed an increase from summer through fall/autumn. On average, ambient sound levels were lowest in summer and increased late 2021 through 2022 with most temporal variability occurring across lower frequencies. The area showed a complex soundscape with several species sharing time–frequency space as well as overlap of vessel noise with the communication range of all baleen whale species.},
	pages = {fsad148},
	journaltitle = {{ICES} Journal of Marine Science},
	shortjournal = {{ICES} Journal of Marine Science},
	author = {Van Parijs, S M and {DeAngelis}, A I and Aldrich, T and Gordon, R and Holdman, A and {McCordic}, J A and Mouy, X and Rowell, T J and Tennant, S and Westell, A and Davis, G E},
	urldate = {2023-10-02},
	date = {2023-09-30},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\I2DLRFFI\\Van Parijs et al. - 2023 - Establishing baselines for predicting change in am.pdf:application/pdf},
}

@inproceedings{bolgan_fish_2019,
	title = {Fish biophony in a Mediterranean submarine canyon: a preliminary investigation using Static Acoustic Monitoring and gliders},
	url = {https://orbi.uliege.be/handle/2268/239504},
	shorttitle = {Fish biophony in a Mediterranean submarine canyon},
	abstract = {Submarine canyons are key structures for ecosystem functioning in the Mediterranean Sea. This study was conducted in the canyon of Calvi (North-West Corsica, France) by using a combination of Static Acoustic Monitoring ({SAM}) and hydrophone integrated gliders (Seaexplorer, Alseamar). During summer 2016 and 2017, three {SAM} campaigns (-125 m to -150 m, 3 kilometers from coastline) and one gliders mission (-900 m to -60 m, 6 kilometers to 3 kilometers from coastline) were here conducted. A total of 194 hours of recordings were analysed for fish sound diversity (i.e. number of sound types) and for fish sound abundance (number of sounds per sound type and per unit of time). 
 
Biological sounds were detected in 37\% of the recorded audio files. Besides for the presence of marine mammals clicks and whistles, at least 9 sound types (for a total of more than 8.000 sounds) with characteristics similar to those emitted by known vocal fish species were characterised; for one of these, emitter identity could be inferred at the genus level (Ophidion sp.). Furthermore, an increase in Sea Ambient Noise between 10 and 15 {dB} re 1 µPa was observed during daytime hours due to boat traffic. 
 
The vastness of the deep-sea and, in particular, the heterogeneity of submarine canyons, their high biodiversity and level of fauna specificity, together with the very localized character of observations carried out to date fully justify the use of an holistic monitoring approach such as {PAM}, especially when a combination of methods is used (e.g. {SAM} and gliders). Our study demonstrate that {PAM} can provide novel information about the ecoacoustics and the distribution of vocal fish species in these pivotal Mediterranean environments and can assess the contribution of anthropogenic sound and their adverse effects (such as masking) on fishes.},
	eventtitle = {2019 {EFFECTS} {OF} {NOISE} {ON} {AQUATIC} {LIFE}},
	author = {Bolgan, Marta and Gervaise, Cedric and Di Iorio, Lucia and Lussent, Julie and Lejeune, Pierre and Raick, Xavier and Parmentier, Eric},
	urldate = {2023-10-02},
	date = {2019-07-10},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\HJXAX9YV\\Bolgan et al. - 2019 - Fish biophony in a Mediterranean submarine canyon.pdf:application/pdf},
}

@article{carretta_us_2023,
	title = {U.S. Pacific marine mammal stock assessments: 2022},
	url = {https://repository.library.noaa.gov/view/noaa/51022},
	doi = {10.25923/5YSF-GT95},
	shorttitle = {U.S. Pacific marine mammal stock assessments},
	author = {Carretta, James V.},
	urldate = {2023-10-25},
	date = {2023},
	note = {Publisher: Southwest Fisheries Science Center (U.S.).},
}

@article{newsom_2023_2023,
	title = {2023 {CALIFORNIA} {COMMERCIAL} {FISHING} {REGULATIONS} {DIGEST}},
	author = {Newsom, Gavin},
	date = {2023},
	langid = {english},
	file = {FileHandler.pdf:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\ZJMLUVBP\\FileHandler.pdf:application/pdf},
}

@inproceedings{wiggins_high-frequency_2007,
	location = {Tokyo, Japan},
	title = {High-frequency Acoustic Recording Package ({HARP}) for broad-band, long-term marine mammal monitoring},
	isbn = {978-1-4244-1207-5 978-1-4244-1208-2},
	url = {http://ieeexplore.ieee.org/document/4231090/},
	doi = {10.1109/UT.2007.370760},
	abstract = {Advancements in low-power and high-data-capacity consumer computer technology during the past decade have been adapted to autonomously record sounds from marine mammals over long periods. Acoustic monitoring has advantages over traditional visual surveys including greater detection ranges, continuous long-term monitoring in remote locations under various weather conditions and independent of daylight, and lower cost. However, until recently, the technology required to autonomously record whale sounds over long durations has been limited to low-frequency ({\textless} 1000 Hz) baleen whales. The need for a broader-band, higher-data capacity system capable of autonomously recording toothed whales and other marine mammals for long periods has prompted the development of a High-frequency Acoustic Recording Package ({HARP}) capable of sample rates up to 200 {kHz}. Currently, {HARPs} accumulate data at a rate of almost 2 {TB} per instrument deployment which creates challenges for processing these large data sets. One method we employ to address some of these challenges is a spectral averaging algorithm in which the data are compressed and viewed as long duration spectrograms. These spectrograms provide the ability to view large amounts of data quickly for events of interest, and they provide a link for quickly accessing the short time-scale data for more detailed analysis. {HARPs} are currently in use worldwide to acoustically monitor marine mammals for behavioral and ecological long-term studies. The {HARP} design is described and data analysis strategies along with software tools are discussed using examples of broad-band recorded data.},
	eventtitle = {2007 Symposium on Underwater Technology and Workshop on Scientific Use of Submarine Cables and Related Technologies},
	pages = {551--557},
	booktitle = {2007 Symposium on Underwater Technology and Workshop on Scientific Use of Submarine Cables and Related Technologies},
	publisher = {{IEEE}},
	author = {Wiggins, Sean M. and Hildebrand, John A.},
	urldate = {2023-11-30},
	date = {2007-04},
	langid = {english},
	file = {Wiggins and Hildebrand - 2007 - High-frequency Acoustic Recording Package (HARP) f.pdf:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\FXZS4ATN\\Wiggins and Hildebrand - 2007 - High-frequency Acoustic Recording Package (HARP) f.pdf:application/pdf},
}

@article{denes_assessing_2014,
	title = {Assessing the cross platform performance of marine mammal indicators between two collocated acoustic recorders},
	volume = {21},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S157495411300099X},
	doi = {10.1016/j.ecoinf.2013.10.005},
	series = {Ecological Acoustics},
	abstract = {Equipment and deployment strategies for remote passive acoustic sensing of marine environments must balance memory capacity, power requirements, sampling rate, duty-cycle, deployment duration, instrument size, and environmental concerns. The impact of different parameters on the data and applicability of the data to the specific questions being asked should be considered before deployment. Here we explore the effect of recording and detection parameters on marine mammal acoustic data across two platforms. Daily classifications of marine mammal vocalizations from two passive acoustic monitors with different subsampling parameters, an {AURAL} and a Passive Aquatic Listener ({PAL}), collocated in the Bering Sea were compared. The {AURAL} subsampled on a pre-set schedule, whereas the {PAL} sampled via an adaptive protocol. Detected signals of interest were manually classified in each dataset independently. The daily classification rates of vocalizations were similar. Detections from the higher duty-cycle but lower sample rate {AURAL} were limited to species and vocalizations with energy below 4kHz precluding detection of echolocation signals. Temporal coverage from the {PAL} audio files was limited by the adaptive sub-sampling protocol. A method for classifying ribbon (Histriophoca fasciata) and bearded seal (Erignathus barbatus) vocalizations from the sparse spectral time histories of the {PAL} was developed. Although application of the acoustic entropy as a rapid assessment of biodiversity was not reflective of the number of species detected, acoustic entropy was robust to changes in sample rate and window length.},
	pages = {74--80},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Denes, Samuel L. and Miksis-Olds, Jennifer L. and Mellinger, David K. and Nystuen, Jeffrey A.},
	urldate = {2024-01-08},
	date = {2014-05-01},
	keywords = {Acoustic diversity, Acoustic entropy, Marine mammal classification, Ocean acoustics, Spectral detection},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\W3SRJHT5\\S157495411300099X.html:text/html},
}

@article{padovese_adapting_2023,
	title = {Adapting deep learning models to new acoustic environments - A case study on the North Atlantic right whale upcall},
	volume = {77},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S157495412300198X},
	doi = {10.1016/j.ecoinf.2023.102169},
	abstract = {Passive acoustic monitoring is increasingly being used for studying marine mammals, leading to the accumulation of large acoustic datasets. Analyzing these datasets becomes impractical without automated detection and classification software. Detectors and classifiers based on deep neural networks have shown great potential, but their performance is often limited by the availability of sufficient quantities of annotated training samples, and their application restricted to the specific acoustic environment(s) from which their training data were collected. We address these limitations by employing transfer learning, a deep learning concept whereby knowledge from a source domain is transferred to a target domain. Specifically, we considered two different underwater acoustic environments as the source and target domains. The objective was to use a deep neural network that had been trained in one environment with abundant annotated training samples, and optimize its performance in the other environment where the annotated training samples were limited. Training and testing were conducted using three acoustic datasets containing North Atlantic right whale (Eubalaena glacialis) upcalls. Experiments show that adapting a trained model to the new environment led to a substantial improvement in recall from 70\% to 85\%, while maintaining a low false-positive rate of less than 5 per hour. The methodology is implemented as an open-source Python tool to facilitate the creation of more tailored deep learning-based acoustic detectors and classifiers for North Atlantic right whale vocalizations and other stereotyped marine mammal calls.},
	pages = {102169},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Padovese, Bruno and Kirsebom, Oliver S. and Frazao, Fabio and Evers, Clair H. M. and Beslin, Wilfried A. M. and Theriault, Jim and Matwin, Stan},
	urldate = {2024-01-08},
	date = {2023-11-01},
	keywords = {Deep learning, North Atlantic right whales, Underwater bioacoustics},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\2WLM9T22\\S157495412300198X.html:text/html},
}

@article{teixeira_fledge_2022,
	title = {Fledge or fail: Nest monitoring of endangered black-cockatoos using bioacoustics and open-source call recognition},
	volume = {69},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954122001054},
	doi = {10.1016/j.ecoinf.2022.101656},
	shorttitle = {Fledge or fail},
	abstract = {Ecologists are increasingly using bioacoustics in wildlife monitoring programs. Remote autonomous sound recorders provide new options for collecting data for species and in contexts that were previously difficult. However, post-processing of sound files to extract relevant data remains a significant challenge. Detection algorithms, or call recognizers, can aid automation of species detection but their performance and reliability has been mixed. Further, building recognizers typically requires either costly commercial software or expert programming skills, both of which reduces their accessibility to ecologists responsible for monitoring. In this study we investigated the performance of open-source call recognizers provided by the {monitoR} package in R, a language popular among ecologists. We tested recognizers on sound data collected under natural conditions at nests of two endangered subspecies of black-cockatoo, the Kangaroo Island glossy black-cockatoo Calyptorhynchus lathami halmaturinus (n = 23 nests), and the south-eastern red-tailed black-cockatoo Calyptorhynchus banksii graptogyne (n = 20 nests). Specifically, we tested the performance of binary point matching recognizers in confirming daily nest activity (active or inactive) and nesting outcome (fledge or fail). We tested recognizers on recordings from nests of known status using 3 × 3-h recordings per nest, from early, mid and late stages of the recording period. Daily nest activity was correctly assigned in 61.7\% of survey days analysed (n = 60 days) for the red-tailed black-cockatoo, and 62.3\% of survey days (n = 69 days) for the glossy black-cockatoo. Fledging was successfully detected in all cases. Precision (true positive / true positive + false positive) of individual detections was 70.2\% for the south-eastern red-tailed black-cockatoo and 37.1\% for the Kangaroo Island glossy black-cockatoo. Manual verification of outputs is still required, but it is not necessary to verify all detections to confirm an active nest (i.e., nest is deemed active when true positives are identified). We conclude that bioacoustics combined with semi-automated post-processing can be an appropriate tool for nest monitoring in these endangered subspecies.},
	pages = {101656},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Teixeira, Daniella and Linke, Simon and Hill, Richard and Maron, Martine and van Rensburg, Berndt J.},
	urldate = {2024-01-08},
	date = {2022-07-01},
	keywords = {Monitoring, Bioacoustics, Black-cockatoo, Breeding success, Call recognizer},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\A5U6QUYV\\S1574954122001054.html:text/html},
}

@article{ross_random_2014,
	title = {Random Forest for improved analysis efficiency in passive acoustic monitoring},
	volume = {21},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954113001234},
	doi = {10.1016/j.ecoinf.2013.12.002},
	series = {Ecological Acoustics},
	abstract = {Passive acoustic monitoring often leads to large quantities of sound data which are burdensome to process, such that the availability and cost of expert human analysts can be a bottleneck and make ecosystem or landscape-scale projects infeasible. This manuscript presents a method for rapidly analyzing the results of band-limited energy detectors, which are commonly used for the detection of passerine nocturnal flight calls, but which typically are beset by high false positive rates. We first manually classify a subset of the detected events as signals of interest or false detections. From that subset, we build a Random Forest model to eliminate most of the remaining events as false detections without further human inspection. The overall reduction in the labor required to separate signals of interest from false detections can be 80\% or more. Additionally, we present an R package, flightcallr, containing functions which can be used to implement this new workflow.},
	pages = {34--39},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Ross, Jesse C. and Allen, Paul E.},
	urldate = {2024-01-08},
	date = {2014-05-01},
	keywords = {Bioacoustics, Machine learning, Random Forest, Nocturnal flight call, Workflow},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\7UD5TR6Y\\S1574954113001234.html:text/html},
}

@article{kahl_birdnet_2021,
	title = {{BirdNET}: A deep learning solution for avian diversity monitoring},
	volume = {61},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954121000273},
	doi = {10.1016/j.ecoinf.2021.101236},
	shorttitle = {{BirdNET}},
	abstract = {Variation in avian diversity in space and time is commonly used as a metric to assess environmental changes. Conventionally, such data were collected by expert observers, but passively collected acoustic data is rapidly emerging as an alternative survey technique. However, efficiently extracting accurate species richness data from large audio datasets has proven challenging. Recent advances in deep artificial neural networks ({DNNs}) have transformed the field of machine learning, frequently outperforming traditional signal processing techniques in the domain of acoustic event detection and classification. We developed a {DNN}, called {BirdNET}, capable of identifying 984 North American and European bird species by sound. Our task-specific model architecture was derived from the family of residual networks ({ResNets}), consisted of 157 layers with more than 27 million parameters, and was trained using extensive data pre-processing, augmentation, and mixup. We tested the model against three independent datasets: (a) 22,960 single-species recordings; (b) 286 h of fully annotated soundscape data collected by an array of autonomous recording units in a design analogous to what researchers might use to measure avian diversity in a field setting; and (c) 33,670 h of soundscape data from a single high-quality omnidirectional microphone deployed near four {eBird} hotspots frequented by expert birders. We found that domain-specific data augmentation is key to build models that are robust against high ambient noise levels and can cope with overlapping vocalizations. Task-specific model designs and training regimes for audio event recognition perform on-par with very complex architectures used in other domains (e.g., object detection in images). We also found that high temporal resolution of input spectrograms (short {FFT} window length) improves the classification performance for bird sounds. In summary, {BirdNET} achieved a mean average precision of 0.791 for single-species recordings, a F0.5 score of 0.414 for annotated soundscapes, and an average correlation of 0.251 with hotspot observation across 121 species and 4 years of audio data. By enabling the efficient extraction of the vocalizations of many hundreds of bird species from potentially vast amounts of audio data, {BirdNET} and similar tools have the potential to add tremendous value to existing and future passively collected audio datasets and may transform the field of avian ecology and conservation.},
	pages = {101236},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Kahl, Stefan and Wood, Connor M. and Eibl, Maximilian and Klinck, Holger},
	urldate = {2024-01-08},
	date = {2021-03-01},
	keywords = {Bioacoustics, Conservation, Deep learning, Convolutional neural networks, Passive acoustic monitoring, Avian diversity, Bird sound recognition},
}

@article{kahl_birdnet_2021-1,
	title = {{BirdNET}: A deep learning solution for avian diversity monitoring},
	volume = {61},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954121000273},
	doi = {10.1016/j.ecoinf.2021.101236},
	shorttitle = {{BirdNET}},
	abstract = {Variation in avian diversity in space and time is commonly used as a metric to assess environmental changes. Conventionally, such data were collected by expert observers, but passively collected acoustic data is rapidly emerging as an alternative survey technique. However, efficiently extracting accurate species richness data from large audio datasets has proven challenging. Recent advances in deep artificial neural networks ({DNNs}) have transformed the field of machine learning, frequently outperforming traditional signal processing techniques in the domain of acoustic event detection and classification. We developed a {DNN}, called {BirdNET}, capable of identifying 984 North American and European bird species by sound. Our task-specific model architecture was derived from the family of residual networks ({ResNets}), consisted of 157 layers with more than 27 million parameters, and was trained using extensive data pre-processing, augmentation, and mixup. We tested the model against three independent datasets: (a) 22,960 single-species recordings; (b) 286 h of fully annotated soundscape data collected by an array of autonomous recording units in a design analogous to what researchers might use to measure avian diversity in a field setting; and (c) 33,670 h of soundscape data from a single high-quality omnidirectional microphone deployed near four {eBird} hotspots frequented by expert birders. We found that domain-specific data augmentation is key to build models that are robust against high ambient noise levels and can cope with overlapping vocalizations. Task-specific model designs and training regimes for audio event recognition perform on-par with very complex architectures used in other domains (e.g., object detection in images). We also found that high temporal resolution of input spectrograms (short {FFT} window length) improves the classification performance for bird sounds. In summary, {BirdNET} achieved a mean average precision of 0.791 for single-species recordings, a F0.5 score of 0.414 for annotated soundscapes, and an average correlation of 0.251 with hotspot observation across 121 species and 4 years of audio data. By enabling the efficient extraction of the vocalizations of many hundreds of bird species from potentially vast amounts of audio data, {BirdNET} and similar tools have the potential to add tremendous value to existing and future passively collected audio datasets and may transform the field of avian ecology and conservation.},
	pages = {101236},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Kahl, Stefan and Wood, Connor M. and Eibl, Maximilian and Klinck, Holger},
	urldate = {2024-01-08},
	date = {2021-03-01},
	keywords = {Bioacoustics, Conservation, Deep learning, Convolutional neural networks, Passive acoustic monitoring, Avian diversity, Bird sound recognition},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\XC9FBQJP\\S1574954121000273.html:text/html},
}

@online{noauthor_scopus_nodate,
	title = {Scopus preview - Scopus - Document details - Ensemble of convolutional neural networks to improve animal audio classification},
	url = {https://www.scopus.com/record/display.uri?eid=2-s2.0-85085502755&origin=inward&txGid=2ad864ed988d2a0e7a9be1f7b18a82bf},
	abstract = {{TEST} 02 - Elsevier's Scopus, the largest abstract and citation database of peer-reviewed literature. Search and access research from the science, technology, medicine, social sciences and arts and humanities fields.},
	urldate = {2024-01-08},
	langid = {american},
	doi = {10.1186/s13636-020-00175-3},
	file = {Full Text:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\EMA7YDYZ\\Scopus preview - Scopus - Document details - Ensem.pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\CFHQU9TP\\display.html:text/html},
}

@article{marcus_deep_nodate,
	title = {Deep Learning: A Critical Appraisal},
	abstract = {Although deep learning has historical roots going back decades, neither the term “deep learning” nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton’s now classic 2012 (Krizhevsky, Sutskever, \& Hinton, 2012)deep net model of Imagenet.},
	author = {Marcus, Gary},
	langid = {english},
	file = {Marcus - Deep Learning A Critical Appraisal.pdf:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\9LQW35TP\\Marcus - Deep Learning A Critical Appraisal.pdf:application/pdf},
}

@online{noauthor_scopus_nodate-1,
	title = {Scopus preview - Scopus - Document details - A survey on Image Data Augmentation for Deep Learning},
	url = {https://www.scopus.com/record/display.uri?eid=2-s2.0-85068705129&origin=inward&txGid=00a8e248d5bfaaa446708c5b4ed00828},
	abstract = {{TEST} 02 - Elsevier's Scopus, the largest abstract and citation database of peer-reviewed literature. Search and access research from the science, technology, medicine, social sciences and arts and humanities fields.},
	urldate = {2024-01-08},
	langid = {american},
	doi = {10.1186/s40537-019-0197-0},
	file = {Full Text:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\KFYJUT2B\\Scopus preview - Scopus - Document details - A sur.pdf:application/pdf;Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\JYTGTHGC\\display.html:text/html},
}

@article{nguyen_hong_duc_assessing_2021,
	title = {Assessing inter-annotator agreement from collaborative annotation campaign in marine bioacoustics},
	volume = {61},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954120301357},
	doi = {10.1016/j.ecoinf.2020.101185},
	abstract = {It is currently widely recognized that automated methods are crucial to help processing long-term recordings of marine bioacoustics. To evaluate the efficiency of such methods, it is essential to develop large-scale annotated datasets. However, besides being laborious and resource intensive, recent studies have suggested that such a task could also be highly subjective with the generation of annotator specific errors. In this work, we investigate the question of inter-annotator agreement from a multi-annotator annotation campaign performed on a marine bioacoustics dataset. After providing quantitative evidence of inter-annotator variability, we investigate potential sources on both the user annotation practice and the annotation data and task to better understand why and how such variability occurs. Our study reveals that the acoustic event type, the Signal-to-Noise Ratio of the acoustic event and the annotator profile are three examples of critical factors impacting the annotation results of a multi-annotator campaign.},
	pages = {101185},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Nguyen Hong Duc, Paul and Torterotot, Maëlle and Samaran, Flore and White, Paul R. and Gérard, Odile and Adam, Olivier and Cazau, Dorian},
	urldate = {2024-01-08},
	date = {2021-03-01},
	keywords = {{DCLDE} 2015 low frequency, Marine bioacoustics, Multi-annotator agreement, Reliability},
	file = {Accepted Version:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\T997GWE7\\Nguyen Hong Duc et al. - 2021 - Assessing inter-annotator agreement from collabora.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\DZDVAY2J\\S1574954120301357.html:text/html},
}

@article{frommolt_applying_2014,
	title = {Applying bioacoustic methods for long-term monitoring of a nocturnal wetland bird},
	volume = {21},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954113001301},
	doi = {10.1016/j.ecoinf.2013.12.009},
	series = {Ecological Acoustics},
	abstract = {Bioacoustic monitoring is becoming more and more popular as a non-invasive method to study populations and communities of vocalizing animals. Acoustic pattern recognition techniques allow for automated identification of species and an estimation of species composition within ecosystems. Here we describe an approach where on the basis of long term acoustic recordings not only the occurrence of a species was documented, but where the number of vocalizing animals was also estimated. This approach allows us to follow up changes in population density and to define breeding sites in a changing environment. We present the results of five years of continuous acoustic monitoring of Eurasian bittern (Botaurus stellaris) in a recent wetland restoration area. Using a setup consisting of four four-channel recorders equipped with cardioid microphones we recorded vocal activity during entire nights. Vocalizations of bitterns were detected on the recordings by spectrogram template matching. On basis of time differences of arrival ({TDOA}) of the acoustic signals at different recording devices booming bitterns could be mapped using hyperbolic localization. During the study period not only changes in the number of calling birds but also changes in their spatial distribution connected with changes in habitat structure could be documented. This semi-automated approach towards monitoring birds described here could be applied to a wide range of monitoring tasks for animals with long distance vocalizations.},
	pages = {4--12},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Frommolt, Karl-Heinz and Tauchert, Klaus-Henry},
	urldate = {2024-01-08},
	date = {2014-05-01},
	keywords = {Acoustic pattern recognition, Bioacoustic monitoring, Hyperbolic localization, Population size},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\PKIQPFL2\\S1574954113001301.html:text/html},
}

@article{znidersic_using_2020,
	title = {Using visualization and machine learning methods to monitor low detectability species—The least bittern as a case study},
	volume = {55},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954119303255},
	doi = {10.1016/j.ecoinf.2019.101014},
	abstract = {Long duration acoustic monitoring is becoming an increasingly popular approach to extend survey effort by using autonomous sensors to passively collect data over large temporal and spatial scales. This is of particular benefit when attempting to detect a species whose temporal vocalization strategy is unknown, and whose small population size reduces detection probability. It is also of benefit in environments that are logistically difficult to access such as wetlands. We investigated the vocalization strategy of the Least Bittern (Ixobrychus exilis), a species of high conservation concern in the Western hemisphere and ‘in need of management’ in multiple states of the {USA}. The Least Bittern is a secretive marsh bird that is primarily detected by its vocalizations and call-playback surveys are typically used for population monitoring. To minimize disturbance to both the birds and their habitat, we deployed autonomous acoustic recording units and collected continuous 24-hour audio recordings for 30 days. The resultant accumulation of data necessitated an automated method to assist with analysis and interpretation. We successfully applied a novel soundscape technique—long-duration, false-color ({LDFC}) spectrograms—to visually confirm presence of Least Bittern from the ‘coo coo coo’ vocalization associated with breeding. In addition, we used a machine learning technique to automate the acoustic event detection process. Peak vocalization times were then predicted from an annotated dataset of actual calls and subsequently used to develop an optimal acoustic survey strategy. The results of this research demonstrate how machine learning methods can search large data sets for a specific species. This information can then be used to optimize existing monitoring methods, to increase detection probability and to minimize associated costs.},
	pages = {101014},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Znidersic, Elizabeth and Towsey, Michael and Roy, W. K. and Darling, Sarah E. and Truskinger, Anthony and Roe, Paul and Watson, David M.},
	urldate = {2024-01-08},
	date = {2020-01-01},
	keywords = {Ecoacoustics, Machine learning, Acoustic ecology, Bird call recognition, Conservation technology, Least Bittern},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\GIFBADA7\\S1574954119303255.html:text/html},
}

@article{sanchez-gendriz_methodology_2017,
	title = {A methodology for analyzing biological choruses from long-term passive acoustic monitoring in natural areas},
	volume = {41},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954117300201},
	doi = {10.1016/j.ecoinf.2017.07.001},
	abstract = {Long-term passive acoustic monitoring can provide important insights on the study of biological choruses, which represent a key component of natural environments. Nowadays, the development of methods for analysis and visualization of large acoustic datasets is an active area of research. In this context, the present paper addresses how the traditional computation of spectrograms and Sound Pressure Levels ({SPL}) could be used for analyzing large sound datasets. Additionally, a visualization tool named here as {SPL}-Gram and a method for automatic detection of trends in dawn and dusk choruses are presented. The dataset used as a case study represents 3months of underwater sound collected in a marine wildlife refuge in southern Brazilian coast. Results reveal events with strong daily periodicity, originated by fish choruses in the frequency band from 0.01–2kHz, and, in the higher frequencies, reflecting acoustic activity of crustaceans. The reported periodicities show a marked relation with sunrise and sunset through the studied period, thus revealing circadian cycles present in the monitored environment. The proposed methodology is not only easy for implementation, but also proves to be valuable in the description of daily and seasonal patterns of biological choruses in large acoustic datasets.},
	pages = {1--10},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Sánchez-Gendriz, I. and Padovese, L. R.},
	urldate = {2024-01-08},
	date = {2017-09-01},
	keywords = {Soundscape ecology, Alcatrazes archipelago wildlife refuge, Biological choruses, Long-term passive acoustic monitoring},
}

@article{truskinger_decision_2015,
	title = {Decision support for the efficient annotation of bioacoustic events},
	volume = {25},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954114001307},
	doi = {10.1016/j.ecoinf.2014.10.001},
	abstract = {Acoustic sensors allow scientists to scale environmental monitoring over large spatiotemporal scales. The faunal vocalisations captured by these sensors can answer ecological questions, however, identifying these vocalisations within recorded audio is difficult: automatic recognition is currently intractable and manual recognition is slow and error prone. In this paper, a semi-automated approach to call recognition is presented. An automated decision support tool is tested that assists users in the manual annotation process. The respective strengths of human and computer analysis are used to complement one another. The tool recommends the species of an unknown vocalisation and thereby minimises the need for the memorization of a large corpus of vocalisations. In the case of a folksonomic tagging system, recommending species tags also minimises the proliferation of redundant tag categories. We describe two algorithms: (1) a “naïve” decision support tool (16\%–64\% sensitivity) with efficiency of O(n) but which becomes unscalable as more data is added and (2) a scalable alternative with 48\% sensitivity and an efficiency {ofO}(logn). The improved algorithm was also tested in a {HTML}-based annotation prototype. The result of this work is a decision support tool for annotating faunal acoustic events that may be utilised by other bioacoustics projects.},
	pages = {14--21},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Truskinger, Anthony and Towsey, Michael and Roe, Paul},
	urldate = {2024-01-08},
	date = {2015-01-01},
	keywords = {Bioacoustics, Annotations, Decision support, Faunal vocalisation, Semi-automated, Similarity search},
}

@article{nolasco_learning_2023,
	title = {Learning to detect an animal sound from five examples},
	volume = {77},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S157495412300287X},
	doi = {10.1016/j.ecoinf.2023.102258},
	abstract = {Automatic detection and classification of animal sounds has many applications in biodiversity monitoring and animal behavior. In the past twenty years, the volume of digitised wildlife sound available has massively increased, and automatic classification through deep learning now shows strong results. However, bioacoustics is not a single task but a vast range of small-scale tasks (such as individual {ID}, call type, emotional indication) with wide variety in data characteristics, and most bioacoustic tasks do not come with strongly-labelled training data. The standard paradigm of supervised learning, focussed on a single large-scale dataset and/or a generic pre-trained algorithm, is insufficient. In this work we recast bioacoustic sound event detection within the {AI} framework of few-shot learning. We adapt this framework to sound event detection, such that a system can be given the annotated start/end times of as few as 5 events, and can then detect events in long-duration audio—even when the sound category was not known at the time of algorithm training. We introduce a collection of open datasets designed to strongly test a system's ability to perform few-shot sound event detections, and we present the results of a public contest to address the task. Our analysis shows that prototypical networks are a very common used strategy and they perform well when enhanced with adaptations for general characteristics of animal sounds. However, systems with high time resolution capabilities perform the best in this challenge. We demonstrate that widely-varying sound event durations are an important factor in performance, as well as non-stationarity, i.e. gradual changes in conditions throughout the duration of a recording. For fine-grained bioacoustic recognition tasks without massive annotated training data, our analysis demonstrate that few-shot sound event detection is a powerful new method, strongly outperforming traditional signal-processing detection methods in the fully automated scenario.},
	pages = {102258},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Nolasco, Ines and Singh, Shubhr and Morfi, Veronica and Lostanlen, Vincent and Strandburg-Peshkin, Ariana and Vidaña-Vila, Ester and Gill, Lisa and Pamuła, Hanna and Whitehead, Helen and Kiskin, Ivan and Jensen, Frants H. and Morford, Joe and Emmerson, Michael G. and Versace, Elisabetta and Grout, Emily and Liu, Haohe and Ghani, Burooj and Stowell, Dan},
	urldate = {2024-01-08},
	date = {2023-11-01},
	keywords = {Bioacoustics, Deep learning, Event detection, Few-shot learning},
	file = {Submitted Version:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\64C9XJKG\\Nolasco et al. - 2023 - Learning to detect an animal sound from five examp.pdf:application/pdf},
}

@article{andreassen_semi-automatic_2014,
	title = {Semi-automatic long-term acoustic surveying: A case study with bats},
	volume = {21},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954113001313},
	doi = {10.1016/j.ecoinf.2013.12.010},
	series = {Ecological Acoustics},
	shorttitle = {Semi-automatic long-term acoustic surveying},
	abstract = {Increasing concern about decline in biodiversity has created a demand for population surveys. Acoustic monitoring is an efficient non-invasive method, which may be deployed for surveys of animals as diverse as insects, birds, and bats. Long-term unmanned automatic monitoring may provide unique unbiased data from a whole season, but the large amount of data presents serious challenges for the automatic processing of the measurements. To demonstrate feasibility of automatic multi-channel surveying using a new prototype hardware, we carried out a 2-month study of echolocating bats requiring high data sampling rates (500kHz). Using a sound energy threshold criterion for triggering recording, we collected 236GB (Gi=10243) of data at full bandwidth. We implemented a simple automatic method using a Support Vector Machine ({SVM}) classifier based on a combination of temporal and spectral analyses to classify events into bat calls and non-bat events. After experimentation we selected duration, energy, bandwidth, and entropy as classification features to identify short high energy structured sounds in the right frequency range. The spectral entropy makes use of the orderly arrangement of frequencies in bat calls to reject short noise pulses, e.g. from rain. The {SVM} classifier reduced our dataset to 162MB of candidate bat calls with an estimated accuracy of 96\% for dry nights and 70\% when it was raining. The automatic survey revealed calls from two species of bat not previously recorded in the area, as well as an unexpected abundance of social calls. The recordings provide data which can be used to correlate bat activity with rain, temperature, and sunset/sunrise. We discuss future applications, achieving higher accuracy in classifying bat calls and the possibility of using trajectory-tracking data to determine bat behavior and correct for the bias toward loud bats inherent in acoustic surveying.},
	pages = {13--24},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Andreassen, Tórur and Surlykke, Annemarie and Hallam, John},
	urldate = {2024-01-08},
	date = {2014-05-01},
	keywords = {Automatic event classification, Automatic event extraction, Long-term multi-channel passive acoustic surveying, Ultrasonic microphone array},
}

@article{morales_method_2022,
	title = {Method for passive acoustic monitoring of bird communities using {UMAP} and a deep neural network},
	volume = {72},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954122003594},
	doi = {10.1016/j.ecoinf.2022.101909},
	abstract = {An effective practice for monitoring bird communities is the recognition and identification of their acoustic signals, whether simple, complex, fixed or variable. A method for the passive monitoring of diversity, activity and acoustic phenology of structural species of a bird community in an annual cycle is presented. The method includes the semi-automatic elaboration of a dataset of 22 vocal and instrumental forms of 16 species. To analyze bioacoustic richness, the {UMAP} algorithm was run on two parallel feature extraction channels. A convolutional neural network was trained using {STFT}-Mel spectrograms to perform the task of automatic identification of bird species. The predictive performance was evaluated by obtaining a minimum average precision of 0.79, a maximum equal to 1.0 and a {mAP} equal to 0.97. The model was applied to a huge set of passive recordings made in a network of urban wetlands for one year. The acoustic activity results were synchronized with climatological temperature data and sunlight hours. The results confirm that the proposed method allows for monitoring a taxonomically diverse group of birds that nourish the annual soundscape of an ecosystem, as well as detecting the presence of cryptic species that often go unnoticed.},
	pages = {101909},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Morales, Gabriel and Vargas, Víctor and Espejo, Diego and Poblete, Víctor and Tomasevic, Jorge A. and Otondo, Felipe and Navedo, Juan G.},
	urldate = {2024-01-08},
	date = {2022-12-01},
	keywords = {Deep learning, Soundscape, Passive acoustic monitoring, Bird community, Phenology},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\Z6BXY3VJ\\S1574954122003594.html:text/html},
}

@article{frainer_automatic_2023,
	title = {Automatic detection and taxonomic identification of dolphin vocalisations using convolutional neural networks for passive acoustic monitoring},
	volume = {78},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954123003205},
	doi = {10.1016/j.ecoinf.2023.102291},
	abstract = {A novel framework for acoustic detection and species identification is proposed to aid passive acoustic monitoring studies on the endangered Indian Ocean humpback dolphin (Sousa plumbea) in South African waters. Convolutional Neural Networks ({CNNs}) were used for both detection and identification of dolphin vocalisations tasks, and performance was evaluated using custom and pre-trained architectures (transfer learning). In total, 723 min of acoustic data were annotated for the presence of whistles, burst pulses and echolocation clicks produced by Delphinus delphis ({\textasciitilde}45.6\%), Tursiops aduncus ({\textasciitilde}39\%), Sousa plumbea ({\textasciitilde}14.4\%), Orcinus orca ({\textasciitilde}1\%). The best performing models for detecting dolphin presence and species identification used segments (spectral windows) of two second lengths and were trained using images with 70 and 90 dpi, respectively. The best detection model was built using a customised architecture and achieved an accuracy of 84.4\% for all dolphin vocalisations on the test set, and 89.5\% for vocalisations with a high signal to noise ratio. The best identification model was also built using the customised architecture and correctly identified S. plumbea (96.9\%), T. aduncus (100\%), and D. delphis (78\%) encounters in the testing dataset. The developed framework was designed based on the knowledge of complex dolphin sounds and it may assists in finding suitable {CNN} hyper-parameters for other species or populations. Our study contributes towards the development of an open-source tool to assist long-term studies of endangered species, living in highly diverse habitats, using passive acoustic monitoring.},
	pages = {102291},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Frainer, Guilherme and Dufourq, Emmanuel and Fearey, Jack and Dines, Sasha and Probert, Rachel and Elwen, Simon and Gridley, Tess},
	urldate = {2024-01-08},
	date = {2023-12-01},
	keywords = {Machine learning, Convolutional neural networks, Sound detection, Passive acoustic monitoring, Indian Ocean humpback dolphin, Species identification},
}

@article{li_model-based_2020,
	title = {Model-based unsupervised clustering for distinguishing Cuvier's and Gervais' beaked whales in acoustic data},
	volume = {58},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954120300443},
	doi = {10.1016/j.ecoinf.2020.101094},
	abstract = {Passive acoustic monitoring ({PAM}), particularly autonomous platforms, offers many advantages in monitoring phonating deep-diving marine mammals in oceanic environment. Relevant data can be obtained day and night continuously over long durations and in any weather conditions. It provides a cost-efficient solution with greater detection ranges when compared to traditional large research vessel and aerial visual surveys requiring keeping expert observers on station for long periods of time and relying on good visibility and calm seas. Therefore, {PAM} is becoming a preferred tool to assess population dynamics trends and health of deep-water marine mammal stocks. However the large volumes of collected data require robust automatic detection and classification algorithms to identify marine mammals in recordings. As for beaked whales, one of the challenging automatic processing goals is the identification of different species to advance our understanding of their role in the marine ecosystem. At present, traditional detection and classification methods employ searches for acoustic events above a user-defined signal-to-noise ratio threshold in the frequency band of interest and further rely on an experienced operator's manual inspection for species classification and removal of false positives. Current passive monitoring data collection systems yield large volumes of acoustic data, therefore a manual classification approach becomes very time-consuming and impractical. This paper focuses on developing a multi-stage automatic classifier for beaked whale species. The proposed method utilizes unsupervised machine clustering of signal attributes extracted from potential detection events flagged by an energy-band detector. The proposed algorithm was benchmarked against a manually annotated workshop dataset and applied to acoustic data collected in the northern Gulf of Mexico. The algorithm classifies beaked whale species in automatic mode with minimal operator involvement only at the validation stage. When compared with the manually annotated classification dataset, the proposed method achieved a recall rate of 82.8\% for Cuvier's and 77.9\% for Gervais' species in automatic mode. New insights on habitat use by different species of beaked whales in the Gulf of Mexico were gained when using the species-specific classifier. The high spatial resolution acoustic monitoring results showed that the habitat preferences of two dominating beaked whale species in the Gulf of Mexico support the habitat division (ecological niche) hypothesis.},
	pages = {101094},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Li, Kun and Sidorovskaia, Natalia A. and Tiemann, Christopher O.},
	urldate = {2024-01-08},
	date = {2020-07-01},
	keywords = {Machine learning, Signal processing, Beaked whale, Underwater acoustics},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\8K9BT4U3\\S1574954120300443.html:text/html},
}

@article{manzano-rubio_low-cost_2022,
	title = {Low-cost open-source recorders and ready-to-use machine learning approaches provide effective monitoring of threatened species},
	volume = {72},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954122003600},
	doi = {10.1016/j.ecoinf.2022.101910},
	abstract = {Passive acoustic monitoring is a powerful tool for monitoring vocally active taxa. Automated signal recognition software reduces the expert time needed for recording analyses and allows researchers and managers to manage large acoustic datasets. The application of state-of-the-art techniques for automated identification, such as Convolutional Neural Networks, may be challenging for ecologists and managers without informatics or engineering expertise. Here, we evaluated the use of {AudioMoth} — a low-cost and open-source sound recorder — to monitor a threatened and patchily distributed species, the Eurasian bittern (Botaurus stellaris). Passive acoustic monitoring was carried out across 17 potential wetlands in north Spain. We also assessed the performance of {BirdNET} — an automated and freely available classifier able to identify over 3000 bird species — and Kaleidoscope Pro — a user-friendly recognition software — to detect the vocalizations and the presence of the target species. The percentage of presences and vocalizations of the Eurasian bittern automatically detected by {BirdNET} and Kaleidoscope Pro software was compared to manual annotations of 205 recordings. The species was effectively recorded up to distances of 801–900 m, with at least 50\% of the vocalizations uttered within that distance being manually detected; this distance was reduced to 601–700 m when considering the analyses carried out using Kaleidoscope Pro. {BirdNET} detected the species in 59 of the 63 (93.7\%) recordings with known presence of the species, while Kaleidoscope detected the bittern in 62 recordings (98.4\%). At the vocalization level, {BirdNet} and Kaleidoscope Pro were able to detect between 76 and 78\%, respectively, of the vocalizations detected by a human observer. Our study highlights the ability of {AudioMoth} for detecting the bittern at large distances, which increases the potential of that technique for monitoring the species at large spatial scales. According to our results, a single {AudioMoth} could be useful for monitoring the species' presence in wetlands of up to 150 ha. Our study proves the utility of passive acoustic monitoring, coupled with {BirdNET} or Kaleidoscope Pro, as an accurate, repeatable, and cost-efficient method for monitoring the Eurasian bittern at large spatial and temporal scales. Nonetheless, further research should evaluate the performance of {BirdNET} on a larger number of species, and under different recording conditions (e.g., more closed habitats), to improve our knowledge about {BirdNET}'s ability to perform bird monitoring. Future studies should also aim to develop an adequate protocol to perform effective passive acoustic monitoring of the Eurasian bittern.},
	pages = {101910},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Manzano-Rubio, Robert and Bota, Gerard and Brotons, Lluís and Soto-Largo, Eduardo and Pérez-Granados, Cristian},
	urldate = {2024-01-08},
	date = {2022-12-01},
	keywords = {Passive acoustic monitoring, Autonomous recording unit, {BirdNET}, Eurasian bittern, Kaleidoscope Pro, Wildlife monitoring},
	file = {Full Text:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\7JNL3ZY2\\Manzano-Rubio et al. - 2022 - Low-cost open-source recorders and ready-to-use ma.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\H48A7VTN\\S1574954122003600.html:text/html},
}

@article{lopez-baucells_stronger_2019,
	title = {Stronger together: Combining automated classifiers with manual post-validation optimizes the workload vs reliability trade-off of species identification in bat acoustic surveys},
	volume = {49},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954118300232},
	doi = {10.1016/j.ecoinf.2018.11.004},
	shorttitle = {Stronger together},
	abstract = {Owing to major technological advances, bioacoustics has become a burgeoning field in ecological research worldwide. Autonomous passive acoustic recorders are becoming widely used to monitor aerial insectivorous bats, and automatic classifiers have emerged to aid researchers in the daunting task of analysing the resulting massive acoustic datasets. However, the scarcity of comprehensive reference call libraries still hampers their wider application in highly diverse tropical assemblages. Capitalizing on a unique acoustic dataset of {\textgreater}650,000 bat call sequences collected over a 3-year period in the Brazilian Amazon, the aims of this study were (a) to assess how pre-identified recordings of free-flying and hand-released bats could be used to train an automatic classification algorithm (random forest), and (b) to optimize acoustic analysis protocols by combining automatic classification with visual post-validation, whereby we evaluated the proportion of sound files to be post-validated for different thresholds of classification accuracy. Classifiers were trained at species or sonotype (group of species with similar calls) level. Random forest models confirmed the reliability of using calls of both free-flying and hand-released bats to train custom-built automatic classifiers. To achieve a general classification accuracy of {\textasciitilde}85\%, random forest had to be trained with at least 500 pulses per species/sonotype. For seven out of 20 sonotypes, the most abundant in our dataset, we obtained high classification accuracy ({\textgreater}90\%). Adopting a desired accuracy probability threshold of 95\% for the random forest classifier, we found that the percentage of sound files required for manual post-validation could be reduced by up to 75\%, a significant saving in terms of workload. Combining automatic classification with manual {ID} through fully customizable classifiers implemented in open-source software as demonstrated here shows great potential to help overcome the acknowledged risks and biases associated with the sole reliance on automatic classification.},
	pages = {45--53},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {López-Baucells, Adrià and Torrent, Laura and Rocha, Ricardo and E.D. Bobrowiec, Paulo and M. Palmeirim, Jorge and F.J. Meyer, Christoph},
	urldate = {2024-01-08},
	date = {2019-01-01},
	keywords = {Echolocation, Bioacoustics, Amazon, Chiroptera, Machine-learning algorithms},
}

@article{dufourq_passive_2022,
	title = {Passive acoustic monitoring of animal populations with transfer learning},
	volume = {70},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954122001388},
	doi = {10.1016/j.ecoinf.2022.101688},
	abstract = {Progress in deep learning, more specifically in using convolutional neural networks ({CNNs}) for the creation of classification models, has been tremendous in recent years. Within bioacoustics research, there has been a large number of recent studies that use {CNNs}. Designing {CNN} architectures from scratch is non-trivial and requires knowledge of machine learning. Furthermore, hyper-parameter tuning associated with {CNNs} is extremely time consuming and requires expensive hardware. In this paper we assess whether it is possible to build good bioacoustic classifiers by adapting and re-using existing {CNNs} pre-trained on the {ImageNet} dataset – instead of designing them from scratch, a strategy known as transfer learning that has proved highly successful in other domains. This study is a first attempt to conduct a large-scale investigation on how transfer learning can be used for passive acoustic monitoring ({PAM}), to simplify the implementation of {CNNs} and the design decisions when creating them, and to remove time consuming hyper-parameter tuning phases. We compare 12 modern {CNN} architectures across 4 passive acoustic datasets that target calls of the Hainan gibbon Nomascus hainanus, the critically endangered black-and-white ruffed lemur Varecia variegata, the vulnerable Thyolo alethe Chamaetylas choloensis, and the Pin-tailed whydah Vidua macroura. We focus our work on data scarcity issues by training {PAM} binary classification models very small datasets, with as few as 25 verified examples. Our findings reveal that transfer learning can result in up to 82\% F1 score while keeping {CNN} implementation details to a minimum, thus rendering this approach accessible, easier to design, and speeding up further vocalisation annotations to create {PAM} robust models.},
	pages = {101688},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Dufourq, Emmanuel and Batist, Carly and Foquet, Ruben and Durbach, Ian},
	urldate = {2024-01-08},
	date = {2022-09-01},
	keywords = {Bioacoustics, Transfer learning, Deep learning, Convolutional neural networks, Vocalisation classification},
	file = {Full Text:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\SMQTUSIT\\Dufourq et al. - 2022 - Passive acoustic monitoring of animal populations .pdf:application/pdf},
}

@article{roman_ruiz_fin_2023,
	title = {Fin whale pulse detection with deep neural networks},
	volume = {77},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954123002728},
	doi = {10.1016/j.ecoinf.2023.102243},
	abstract = {In this paper, we present an application of Deep Neural Networks to the detection of Fin Whales (Balaenoptera physalus) pulses, also known as calls, from very long acoustic recordings. For the purpose of detection, acoustic signals are converted to images using a Fourier transform operation. Therefore, acoustic pulses become specific shapes. The detection of pulses and their seasonal distribution is used by biologists to estimate the presence of animals and understand their behavior, and they have important ecological value. However, the variations in shape and the presence of background noise make detection difficult. The use of automated instruments for this task is crucial to processing the huge amount of data that comes from hundreds of hours of recordings in a fast and effective way. In this work, different network architectures are compared to assess their effectiveness in the task on a subset of recordings. Additionally, these are compared with other Machine Learning methods from the literature. The best performing network architecture is then applied to the whole set, consisting of three months of recordings, showing an accuracy of 81.37\% and a precision of 75\%, comparable to the results obtained with other methods.},
	pages = {102243},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Román Ruiz, M. and Rossi, C. and Esteban, J. A.},
	urldate = {2024-01-08},
	date = {2023-11-01},
	keywords = {Bioacoustics, Passive acoustic monitoring, Deep neural networks, Fin whale, Pattern recognition},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\ETAGYNLT\\S1574954123002728.html:text/html},
}

@article{tabak_automated_2022,
	title = {Automated classification of bat echolocation call recordings with artificial intelligence},
	volume = {68},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954121003174},
	doi = {10.1016/j.ecoinf.2021.101526},
	abstract = {Acoustic recorders are commonly used to remotely monitor and collect data on bats (Order Chiroptera). These efforts result in many acoustic recordings that must be classified by a bat biologist with expertise in call classification in order to obtain useful information. The rarity of this expertise and time constraints have prompted efforts to automatically classify bat species in acoustic recordings using a variety of learning methods. There are several software programs available for this purpose, but they are imperfect and the United States Fish and Wildlife Service often recommends that a qualified acoustic analyst review bat call identifications even if using these software programs. We sought to build a model to classify bat species using modern computer vision techniques. We used images of bat echolocation calls (i.e., plots of the pulses) to train deep learning computer vision models that automatically classify bat calls to species. Our model classifies 10 species, five of which are protected under the Endangered Species Act. We evaluated our models using standard model validation procedures, and performed two external tests. For these tests, an entire dataset was withheld from the procedure before splitting the data into training and validation sets. We found that our validation accuracy (92\%) and testing accuracy (90\%) were higher than when we used Kaleidoscope Pro and {BCID} software (65\% and 61\% accuracy, respectively) to evaluate the same calls. Our results suggest that our approach is effective at classifying bat species from acoustic recordings, and our trained model will be incorporated into new bat call identification software: {WEST}-{EchoVision}.},
	pages = {101526},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Tabak, Michael A. and Murray, Kevin L. and Reed, Ashley M. and Lombardi, John A. and Bay, Kimberly J.},
	urldate = {2024-01-08},
	date = {2022-05-01},
	keywords = {Echolocation, Deep learning, Bats, Computer vision, Passive sampling, Threatened and endangered species},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\VNNTV8RA\\S1574954121003174.html:text/html;Submitted Version:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\K8DL7AXF\\Tabak et al. - 2022 - Automated classification of bat echolocation call .pdf:application/pdf},
}

@article{bianco_machine_2019,
	title = {Machine learning in acoustics: Theory and applications},
	volume = {146},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/1.5133944},
	doi = {10.1121/1.5133944},
	shorttitle = {Machine learning in acoustics},
	abstract = {Acoustic data provide scientific and engineering insights in fields ranging from biology and communications to ocean and Earth science. We survey the recent advances and transformative potential of machine learning ({ML}), including deep learning, in the field of acoustics. {ML} is a broad family of techniques, which are often based in statistics, for automatically detecting and utilizing patterns in data. Relative to conventional acoustics and signal processing, {ML} is data-driven. Given sufficient training data, {ML} can discover complex relationships between features and desired labels or actions, or between features themselves. With large volumes of training data, {ML} can discover models describing complex acoustic phenomena such as human speech and reverberation. {ML} in acoustics is rapidly developing with compelling results and significant future promise. We first introduce {ML}, then highlight {ML} developments in four acoustics research areas: source localization in speech processing, source localization in ocean acoustics, bioacoustics, and environmental sounds in everyday scenes.},
	pages = {3590--3628},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Bianco, Michael J. and Gerstoft, Peter and Traer, James and Ozanich, Emma and Roch, Marie A. and Gannot, Sharon and Deledalle, Charles-Alban},
	urldate = {2024-01-12},
	date = {2019-11-27},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\48Q3PE7N\\Bianco et al. - 2019 - Machine learning in acoustics Theory and applicat.pdf:application/pdf},
}

@article{stowell_computational_2022,
	title = {Computational bioacoustics with deep learning: a review and roadmap},
	volume = {10},
	issn = {2167-8359},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8944344/},
	doi = {10.7717/peerj.13152},
	shorttitle = {Computational bioacoustics with deep learning},
	abstract = {Animal vocalisations and natural soundscapes are fascinating objects of study, and contain valuable evidence about animal behaviours, populations and ecosystems. They are studied in bioacoustics and ecoacoustics, with signal processing and analysis an important component. Computational bioacoustics has accelerated in recent decades due to the growth of affordable digital sound recording devices, and to huge progress in informatics such as big data, signal processing and machine learning. Methods are inherited from the wider field of deep learning, including speech and image processing. However, the tasks, demands and data characteristics are often different from those addressed in speech or music analysis. There remain unsolved problems, and tasks for which evidence is surely present in many acoustic signals, but not yet realised. In this paper I perform a review of the state of the art in deep learning for computational bioacoustics, aiming to clarify key concepts and identify and analyse knowledge gaps. Based on this, I offer a subjective but principled roadmap for computational bioacoustics with deep learning: topics that the community should aim to address, in order to make the most of future developments in {AI} and informatics, and to use audio data in answering zoological and ecological questions.},
	pages = {e13152},
	journaltitle = {{PeerJ}},
	shortjournal = {{PeerJ}},
	author = {Stowell, Dan},
	urldate = {2024-01-12},
	date = {2022-03-21},
	pmid = {35341043},
	pmcid = {PMC8944344},
	file = {PubMed Central Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\WG37BVLN\\Stowell - 2022 - Computational bioacoustics with deep learning a r.pdf:application/pdf},
}

@article{mutanu_review_2022,
	title = {A Review of Automated Bioacoustics and General Acoustics Classification Research},
	volume = {22},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/21/8361},
	doi = {10.3390/s22218361},
	abstract = {Automated bioacoustics classification has received increasing attention from the research community in recent years due its cross-disciplinary nature and its diverse application. Applications in bioacoustics classification range from smart acoustic sensor networks that investigate the effects of acoustic vocalizations on species to context-aware edge devices that anticipate changes in their environment adapt their sensing and processing accordingly. The research described here is an in-depth survey of the current state of bioacoustics classification and monitoring. The survey examines bioacoustics classification alongside general acoustics to provide a representative picture of the research landscape. The survey reviewed 124 studies spanning eight years of research. The survey identifies the key application areas in bioacoustics research and the techniques used in audio transformation and feature extraction. The survey also examines the classification algorithms used in bioacoustics systems. Lastly, the survey examines current challenges, possible opportunities, and future directions in bioacoustics.},
	pages = {8361},
	number = {21},
	journaltitle = {Sensors},
	author = {Mutanu, Leah and Gohil, Jeet and Gupta, Khushi and Wagio, Perpetua and Kotonya, Gerald},
	urldate = {2024-01-12},
	date = {2022-01},
	langid = {english},
	note = {Number: 21
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {bioacoustics, acoustic detection, general acoustics, review, sound classification, survey},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\AU6G3EV9\\Mutanu et al. - 2022 - A Review of Automated Bioacoustics and General Aco.pdf:application/pdf},
}

@article{frasier_automated_2017,
	title = {Automated classification of dolphin echolocation click types from the Gulf of Mexico},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005823},
	doi = {10.1371/journal.pcbi.1005823},
	abstract = {Delphinids produce large numbers of short duration, broadband echolocation clicks which may be useful for species classification in passive acoustic monitoring efforts. A challenge in echolocation click classification is to overcome the many sources of variability to recognize underlying patterns across many detections. An automated unsupervised network-based classification method was developed to simulate the approach a human analyst uses when categorizing click types: Clusters of similar clicks were identified by incorporating multiple click characteristics (spectral shape and inter-click interval distributions) to distinguish within-type from between-type variation, and identify distinct, persistent click types. Once click types were established, an algorithm for classifying novel detections using existing clusters was tested. The automated classification method was applied to a dataset of 52 million clicks detected across five monitoring sites over two years in the Gulf of Mexico ({GOM}). Seven distinct click types were identified, one of which is known to be associated with an acoustically identifiable delphinid (Risso’s dolphin) and six of which are not yet identified. All types occurred at multiple monitoring locations, but the relative occurrence of types varied, particularly between continental shelf and slope locations. Automatically-identified click types from autonomous seafloor recorders without verifiable species identification were compared with clicks detected on sea-surface towed hydrophone arrays in the presence of visually identified delphinid species. These comparisons suggest potential species identities for the animals producing some echolocation click types. The network-based classification method presented here is effective for rapid, unsupervised delphinid click classification across large datasets in which the click types may not be known a priori.},
	pages = {e1005823},
	number = {12},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Frasier, Kaitlin E. and Roch, Marie A. and Soldevilla, Melissa S. and Wiggins, Sean M. and Garrison, Lance P. and Hildebrand, John A.},
	urldate = {2024-01-12},
	date = {2017-12-07},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Marine mammals, Dolphins, Echolocation, Beaked whales, Bioacoustics, Gulf of Mexico, Killer whales, Pilot whales},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\2ERTEIWX\\Frasier et al. - 2017 - Automated classification of dolphin echolocation c.pdf:application/pdf},
}

@article{zhong_beluga_2020,
	title = {Beluga whale acoustic signal classification using deep learning neural network models},
	volume = {147},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/10.0000921},
	doi = {10.1121/10.0000921},
	abstract = {Over a decade after the Cook Inlet beluga (Delphinapterus leucas) was listed as endangered in 2008, the population has shown no sign of recovery. Lack of ecological knowledge limits the understanding of, and ability to manage, potential threats impeding recovery of this declining population. National Oceanic and Atmospheric Administration Fisheries, in partnership with the Alaska Department of Fish and Game, initiated a passive acoustics monitoring program in 2017 to investigate beluga seasonal occurrence by deploying a series of passive acoustic moorings. Data have been processed with semi-automated tonal detectors followed by time intensive manual validation. To reduce this labor intensive and time-consuming process, in addition to increasing the accuracy of classification results, the authors constructed an ensembled deep learning convolutional neural network model to classify beluga detections as true or false. Using a 0.5 threshold, the final model achieves 96.57\% precision and 92.26\% recall on testing dataset. This methodology proves to be successful at classifying beluga signals, and the framework can be easily generalized to other acoustic classification problems.},
	pages = {1834--1841},
	number = {3},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Zhong, Ming and Castellote, Manuel and Dodhia, Rahul and Lavista Ferres, Juan and Keogh, Mandy and Brewer, Arial},
	urldate = {2024-01-12},
	date = {2020-03-23},
	file = {Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\EM2D9RJV\\Beluga-whale-acoustic-signal-classification-using.html:text/html},
}

@article{kirsebom_meridian_2022,
	title = {{MERIDIAN} open-source software for deep learning-based acoustic data analysis},
	volume = {151},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/10.0010545},
	doi = {10.1121/10.0010545},
	abstract = {Deep neural networks have the potential to transform our approach to developing acoustic detection and classification models, enabling acousticians to develop or re-purpose such models through a fully data-driven approach requiring minimal knowledge of signal processing, algorithm design, and programming. However, open-source software to facilitate this data-driven workflow is currently lacking. {MERIDIAN} is working towards filling this gap through the development of several open-source software products, including the Python package Ketos and the {MAIPL} (Marine {AI} {PLatform}) suite of web applications. While Ketos provides a high-level programming interface for training deep neural networks at detecting and classifying sounds, {MAIPL} is a modular cloud computing service that supports the full model-development workflow. In this contribution, an overview of Ketos and {MAIPL} will be given and their functionalities will be demonstrated through their application to the {HALLO} (Humans and {ALgorithms} Listening for Orcas) project. We highlight one of the {MAIPL} tools, the {MAIPL}-Annotator, which provides a user-friendly interface for collaboratively annotating sound samples and validating model predictions. Future developments will also be described, highlighting new {MAIPL} applications under development such as the {MAIPL}-Adapter, a tool for adapting acoustic deep learning models to new acoustic environments.},
	pages = {A27},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Kirsebom, Oliver S. and Frazao, Fabio and Padovese, Bruno and Sakib, Sadman and Su, Yue and Matwin, Stan},
	urldate = {2024-01-12},
	date = {2022-04-01},
	file = {Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\NUKDZK68\\MERIDIAN-open-source-software-for-deep-learning.html:text/html},
}

@article{nanni_data_2020,
	title = {Data augmentation approaches for improving animal audio classification},
	volume = {57},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954120300340},
	doi = {10.1016/j.ecoinf.2020.101084},
	abstract = {In this paper we present ensembles of classifiers for automated animal audio classification, exploiting different data augmentation techniques for training Convolutional Neural Networks ({CNNs}). The specific animal audio classification problems are i) birds and ii) cat sounds, whose datasets are freely available. We train five different {CNNs} on the original datasets and on their versions augmented by four augmentation protocols, working on the raw audio signals or their representations as spectrograms. We compared our best approaches with the state of the art, showing that we obtain the best recognition rate on the same datasets, without ad hoc parameter optimization. Our study shows that different {CNNs} can be trained for the purpose of animal audio classification and that their fusion works better than the stand-alone classifiers. To the best of our knowledge this is the largest study on data augmentation for {CNNs} in animal audio classification audio datasets using the same set of classifiers and parameters. Our {MATLAB} code is available at https://github.com/{LorisNanni}.},
	pages = {101084},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Nanni, Loris and Maguolo, Gianluca and Paci, Michelangelo},
	urldate = {2024-01-12},
	date = {2020-05-01},
	keywords = {Data augmentation, Pattern recognition, Acoustic features, Animal audio, Audio classification, Ensemble of classifiers},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\82CF5UFT\\S1574954120300340.html:text/html;Submitted Version:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\Q9N546L9\\Nanni et al. - 2020 - Data augmentation approaches for improving animal .pdf:application/pdf},
}

@article{shorten_survey_2019,
	title = {A survey on Image Data Augmentation for Deep Learning},
	volume = {6},
	issn = {2196-1115},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0},
	doi = {10.1186/s40537-019-0197-0},
	abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on {GANs} are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
	pages = {60},
	number = {1},
	journaltitle = {Journal of Big Data},
	shortjournal = {J Big Data},
	author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
	urldate = {2024-01-12},
	date = {2019-12},
	langid = {english},
	file = {Shorten and Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\2Y8AATUP\\Shorten and Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf:application/pdf},
}

@article{li_model-based_2020-1,
	title = {Model-based unsupervised clustering for distinguishing Cuvier's and Gervais' beaked whales in acoustic data},
	volume = {58},
	issn = {1574-9541},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954120300443},
	doi = {10.1016/j.ecoinf.2020.101094},
	abstract = {Passive acoustic monitoring ({PAM}), particularly autonomous platforms, offers many advantages in monitoring phonating deep-diving marine mammals in oceanic environment. Relevant data can be obtained day and night continuously over long durations and in any weather conditions. It provides a cost-efficient solution with greater detection ranges when compared to traditional large research vessel and aerial visual surveys requiring keeping expert observers on station for long periods of time and relying on good visibility and calm seas. Therefore, {PAM} is becoming a preferred tool to assess population dynamics trends and health of deep-water marine mammal stocks. However the large volumes of collected data require robust automatic detection and classification algorithms to identify marine mammals in recordings. As for beaked whales, one of the challenging automatic processing goals is the identification of different species to advance our understanding of their role in the marine ecosystem. At present, traditional detection and classification methods employ searches for acoustic events above a user-defined signal-to-noise ratio threshold in the frequency band of interest and further rely on an experienced operator's manual inspection for species classification and removal of false positives. Current passive monitoring data collection systems yield large volumes of acoustic data, therefore a manual classification approach becomes very time-consuming and impractical. This paper focuses on developing a multi-stage automatic classifier for beaked whale species. The proposed method utilizes unsupervised machine clustering of signal attributes extracted from potential detection events flagged by an energy-band detector. The proposed algorithm was benchmarked against a manually annotated workshop dataset and applied to acoustic data collected in the northern Gulf of Mexico. The algorithm classifies beaked whale species in automatic mode with minimal operator involvement only at the validation stage. When compared with the manually annotated classification dataset, the proposed method achieved a recall rate of 82.8\% for Cuvier's and 77.9\% for Gervais' species in automatic mode. New insights on habitat use by different species of beaked whales in the Gulf of Mexico were gained when using the species-specific classifier. The high spatial resolution acoustic monitoring results showed that the habitat preferences of two dominating beaked whale species in the Gulf of Mexico support the habitat division (ecological niche) hypothesis.},
	pages = {101094},
	journaltitle = {Ecological Informatics},
	shortjournal = {Ecological Informatics},
	author = {Li, Kun and Sidorovskaia, Natalia A. and Tiemann, Christopher O.},
	urldate = {2024-01-12},
	date = {2020-07-01},
	keywords = {Machine learning, Signal processing, Beaked whale, Underwater acoustics},
	file = {ScienceDirect Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\7FCKRG7D\\S1574954120300443.html:text/html},
}

@article{lebien_species-level_2018,
	title = {Species-level classification of beaked whale echolocation signals detected in the northern Gulf of Mexico},
	volume = {144},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/1.5047435},
	doi = {10.1121/1.5047435},
	abstract = {This study presents and evaluates several methods for automated species-level classification of echolocation clicks from three beaked whale species recorded in the northern Gulf of Mexico. The species included are Cuvier's and Gervais' beaked whales, as well as an unknown species denoted Beaked Whale Gulf. An optimal feature set for discriminating the three click types while also separating detected clicks from unidentified delphinids was determined using supervised step-wise discriminant analysis. Linear and quadratic discriminant analyses both achieved error rates below 1\% with three features, determined by tenfold cross validation. The waveform fractal dimension was found to be a highly ranked feature among standard spectral and temporal parameters. The top-ranking features were Higuchi's fractal dimension, spectral centroid, Katz's fractal dimension, and −10 {dB} duration. Six clustering routines, including four popular network-based algorithms, were also evaluated as unsupervised classification methods using the selected feature set. False positive rates of 0.001 and 0.024 were achieved by Chinese Whispers and spectral clustering, respectively, across 200 randomized trials. However, Chinese Whispers clustering yielded larger false negative rates. Spectral clustering was further tested on clicks from encounters of beaked, sperm, and pilot whales in the Tongue of the Ocean, Bahamas.},
	pages = {387--396},
	number = {1},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {{LeBien}, Jack G. and Ioup, Juliette W.},
	urldate = {2024-01-12},
	date = {2018-07-26},
	file = {Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\KJ8766N3\\Species-level-classification-of-beaked-whale.html:text/html},
}

@article{cohen_identification_2022,
	title = {Identification of western North Atlantic odontocete echolocation click types using machine learning and spatiotemporal correlates},
	volume = {17},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0264988},
	doi = {10.1371/journal.pone.0264988},
	abstract = {A combination of machine learning and expert analyst review was used to detect odontocete echolocation clicks, identify dominant click types, and classify clicks in 32 years of acoustic data collected at 11 autonomous monitoring sites in the western North Atlantic between 2016 and 2019. Previously-described click types for eight known odontocete species or genera were identified in this data set: Blainville’s beaked whales (Mesoplodon densirostris), Cuvier’s beaked whales (Ziphius cavirostris), Gervais’ beaked whales (Mesoplodon europaeus), Sowerby’s beaked whales (Mesoplodon bidens), and True’s beaked whales (Mesoplodon mirus), Kogia spp., Risso’s dolphin (Grampus griseus), and sperm whales (Physeter macrocephalus). Six novel delphinid echolocation click types were identified and named according to their median peak frequencies. Consideration of the spatiotemporal distribution of these unidentified click types, and comparison to historical sighting data, enabled assignment of the probable species identity to three of the six types, and group identity to a fourth type. {UD}36, {UD}26, and {UD}28 were attributed to Risso’s dolphin (G. griseus), short-finned pilot whale (G. macrorhynchus), and short-beaked common dolphin (D. delphis), respectively, based on similar regional distributions and seasonal presence patterns. {UD}19 was attributed to one or more species in the subfamily Globicephalinae based on spectral content and signal timing. {UD}47 and {UD}38 represent distinct types for which no clear spatiotemporal match was apparent. This approach leveraged the power of big acoustic and big visual data to add to the catalog of known species-specific acoustic signals and yield new inferences about odontocete spatiotemporal distribution patterns. The tools and call types described here can be used for efficient analysis of other existing and future passive acoustic data sets from this region.},
	pages = {e0264988},
	number = {3},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Cohen, Rebecca E. and Frasier, Kaitlin E. and Baumann-Pickering, Simone and Wiggins, Sean M. and Rafter, Macey A. and Baggett, Lauren M. and Hildebrand, John A.},
	urldate = {2024-01-12},
	date = {2022-03-24},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Acoustics, Dolphins, Beaked whales, Acoustic signals, Bioacoustics, Pilot whales, Sperm whales, Spring},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\SIPU759P\\Cohen et al. - 2022 - Identification of western North Atlantic odontocet.pdf:application/pdf},
}

@article{oswald_tool_2007,
	title = {A tool for real-time acoustic species identification of delphinid whistles},
	volume = {122},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/1.2743157},
	doi = {10.1121/1.2743157},
	abstract = {The ability to identify delphinid vocalizations to species in real-time would be an asset during shipboard surveys. An automated system, Real-time Odontocete Call Classification Algorithm ({ROCCA}), is being developed to allow real-time acoustic species identification in the field. This Matlab-based tool automatically extracts ten variables (beginning, end, minimum and maximum frequencies, duration, slope of the beginning and end sweep, number of inflection points, number of steps, and presence/absence of harmonics) from whistles selected from a real-time scrolling spectrograph ({ISHMAEL}). It uses classification and regression tree analysis ({CART}) and discriminant function analysis ({DFA}) to identify whistles to species. Schools are classified based on running tallies of individual whistle classifications. Overall, 46\% of schools were correctly classified for seven species and one genus (Tursiops truncatus, Stenella attenuata, S. longirostris, S. coeruleoalba, Steno bredanensis, Delphinus species, Pseudorca crassidens, and Globicephala macrorhynchus), with correct classification as high as 80\% for some species. If classification success can be increased, this tool will provide a method for identifying schools that are difficult to approach and observe, will allow species distribution data to be collected when visual efforts are compromised, and will reduce the time necessary for post-cruise data analysis.},
	pages = {587--595},
	number = {1},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Oswald, Julie N. and Rankin, Shannon and Barlow, Jay and Lammers, Marc O.},
	urldate = {2024-01-19},
	date = {2007-07-01},
	file = {Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\W8J59MYH\\A-tool-for-real-time-acoustic-species.html:text/html},
}

@article{baumgartner_generalized_2011,
	title = {A generalized baleen whale call detection and classification system},
	volume = {129},
	issn = {0001-4966},
	url = {https://doi.org/10.1121/1.3562166},
	doi = {10.1121/1.3562166},
	abstract = {Passive acoustic monitoring allows the assessment of marine mammal occurrence and distribution at greater temporal and spatial scales than is now possible with traditional visual surveys. However, the large volume of acoustic data and the lengthy and laborious task of manually analyzing these data have hindered broad application of this technique. To overcome these limitations, a generalized automated detection and classification system ({DCS}) was developed to efficiently and accurately identify low-frequency baleen whale calls. The {DCS} (1) accounts for persistent narrowband and transient broadband noise, (2) characterizes temporal variation of dominant call frequencies via pitch-tracking, and (3) classifies calls based on attributes of the resulting pitch tracks using quadratic discriminant function analysis ({QDFA}). Automated detections of sei whale (Balaenoptera borealis) downsweep calls and North Atlantic right whale (Eubalaena glacialis) upcalls were evaluated using recordings collected in the southwestern Gulf of Maine during the spring seasons of 2006 and 2007. The accuracy of the {DCS} was similar to that of a human analyst: variability in differences between the {DCS} and an analyst was similar to that between independent analysts, and temporal variability in call rates was similar among the {DCS} and several analysts.},
	pages = {2889--2902},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Baumgartner, Mark F. and Mussoline, Sarah E.},
	urldate = {2024-01-19},
	date = {2011-05-10},
	file = {Snapshot:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\T3ZB5T8V\\A-generalized-baleen-whale-call-detection-and.html:text/html;Submitted Version:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\MSBDSWHN\\Baumgartner and Mussoline - 2011 - A generalized baleen whale call detection and clas.pdf:application/pdf},
}

@article{ziegenhorn_discriminating_2022,
	title = {Discriminating and classifying odontocete echolocation clicks in the Hawaiian Islands using machine learning methods},
	volume = {17},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0266424},
	doi = {10.1371/journal.pone.0266424},
	abstract = {Passive acoustic monitoring ({PAM}) has proven a powerful tool for the study of marine mammals, allowing for documentation of biologically relevant factors such as movement patterns or animal behaviors while remaining largely non-invasive and cost effective. From 2008–2019, a set of {PAM} recordings covering the frequency band of most toothed whale (odontocete) echolocation clicks were collected at sites off the islands of Hawaiʻi, Kauaʻi, and Pearl and Hermes Reef. However, due to the size of this dataset and the complexity of species-level acoustic classification, multi-year, multi-species analyses had not yet been completed. This study shows how a machine learning toolkit can effectively mitigate this problem by detecting and classifying echolocation clicks using a combination of unsupervised clustering methods and human-mediated analyses. Using these methods, it was possible to distill ten unique echolocation click ‘types’ attributable to regional odontocetes at the genus or species level. In one case, auxiliary sightings and recordings were used to attribute a new click type to the rough-toothed dolphin, Steno bredanensis. Types defined by clustering were then used as input classes in a neural-network based classifier, which was trained, tested, and evaluated on 5-minute binned data segments. Network precision was variable, with lower precision occurring most notably for false killer whales, Pseudorca crassidens, across all sites (35–76\%). However, accuracy and recall were high ({\textgreater}96\% and {\textgreater}75\%, respectively) in all cases except for one type of short-finned pilot whale, Globicephala macrorhynchus, call class at Kauaʻi and Pearl and Hermes Reef (recall {\textgreater}66\%). These results emphasize the utility of machine learning in analysis of large {PAM} datasets. The classifier and timeseries developed here will facilitate further analyses of spatiotemporal patterns of included toothed whales. Broader application of these methods may improve the efficiency of global multi-species {PAM} data processing for echolocation clicks, which is needed as these datasets continue to grow.},
	pages = {e0266424},
	number = {4},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Ziegenhorn, Morgan A. and Frasier, Kaitlin E. and Hildebrand, John A. and Oleson, Erin M. and Baird, Robin W. and Wiggins, Sean M. and Baumann-Pickering, Simone},
	urldate = {2024-01-22},
	date = {2022-04-12},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Dolphins, Echolocation, Beaked whales, Bioacoustics, Killer whales, Pilot whales, Memory recall, Signal bandwidth},
	file = {Full Text PDF:C\:\\Users\\shannon.rankin.NMFS\\Zotero\\storage\\CWLH5EIK\\Ziegenhorn et al. - 2022 - Discriminating and classifying odontocete echoloca.pdf:application/pdf},
}
